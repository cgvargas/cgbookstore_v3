# ü§ñ Sistema de Agentes para Gera√ß√£o Autom√°tica de Not√≠cias
## CGBookStore v3 - M√≥dulo News

---

**Projeto:** CGBookStore v3  
**M√≥dulo:** `news` (Caminho: `C:\ProjectDjango\cgbookstore_v3\news`)  
**Data:** 18/12/2024  
**Autor:** CGVargas  
**Status:** Planejamento  
**Custo:** R$ 0,00 (Solu√ß√£o 100% Gratuita)

---

## üìã √çNDICE

1. [Vis√£o Geral](#vis√£o-geral)
2. [Objetivos](#objetivos)
3. [Arquitetura da Solu√ß√£o](#arquitetura-da-solu√ß√£o)
4. [Tecnologias Utilizadas](#tecnologias-utilizadas)
5. [Estrutura de Dados](#estrutura-de-dados)
6. [Implementa√ß√£o por Fases](#implementa√ß√£o-por-fases)
7. [APIs e Integra√ß√µes](#apis-e-integra√ß√µes)
8. [Workflow de Automa√ß√£o](#workflow-de-automa√ß√£o)
9. [Custos e Recursos](#custos-e-recursos)
10. [Roadmap de Desenvolvimento](#roadmap-de-desenvolvimento)
11. [Manuten√ß√£o e Monitoramento](#manuten√ß√£o-e-monitoramento)

---

## üéØ VIS√ÉO GERAL

Sistema automatizado de agrega√ß√£o, processamento e publica√ß√£o de not√≠cias liter√°rias para o blog do CGBookStore, utilizando agentes de IA para:

- **Coletar** not√≠cias de m√∫ltiplas fontes RSS
- **Filtrar** conte√∫do relevante sobre literatura, livros e autores
- **Processar** com IA (Gemini + Claude) para criar artigos originais
- **Publicar** automaticamente no blog com imagens e SEO otimizado

### Diferenciais da Solu√ß√£o

‚úÖ **100% Gratuita** - Usa apenas recursos gratuitos e j√° contratados  
‚úÖ **Conte√∫do Original** - IA reescreve not√≠cias para evitar duplica√ß√£o  
‚úÖ **Multi-Fonte** - Agrega de v√°rias fontes RSS confi√°veis  
‚úÖ **SEO-Friendly** - Otimiza√ß√£o autom√°tica para mecanismos de busca  
‚úÖ **Modera√ß√£o** - Sistema de aprova√ß√£o antes da publica√ß√£o  
‚úÖ **Imagens Autom√°ticas** - Busca e adiciona imagens de alta qualidade

---

## üéØ OBJETIVOS

### Objetivos Principais

1. **Automatizar** a cria√ß√£o de conte√∫do para o blog
2. **Reduzir custos** de produ√ß√£o de conte√∫do (R$ 0,00)
3. **Manter frequ√™ncia** de publica√ß√£o (di√°ria/semanal)
4. **Aumentar tr√°fego** org√¢nico atrav√©s de SEO
5. **Engajar audi√™ncia** com conte√∫do relevante sobre literatura

### M√©tricas de Sucesso

- [ ] 30-50 posts/m√™s publicados
- [ ] 0% custo com ferramentas de IA
- [ ] 80%+ aprova√ß√£o de rascunhos gerados
- [ ] Aumento de 50%+ em tr√°fego org√¢nico em 3 meses
- [ ] Tempo m√©dio de modera√ß√£o < 10 min/post

---

## üèóÔ∏è ARQUITETURA DA SOLU√á√ÉO

### Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COLETA DE NOT√çCIAS                       ‚îÇ
‚îÇ  Google News RSS + Feeds Liter√°rios (PublishNews, etc)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               FILTRAGEM COM GEMINI (Gratuito)               ‚îÇ
‚îÇ  ‚Ä¢ Analisa 50-100 not√≠cias coletadas                        ‚îÇ
‚îÇ  ‚Ä¢ Filtra por relev√¢ncia liter√°ria                          ‚îÇ
‚îÇ  ‚Ä¢ Seleciona top 5-10 melhores                              ‚îÇ
‚îÇ  ‚Ä¢ Cria resumos executivos                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          CRIA√á√ÉO COM CLAUDE (J√° contratado)                 ‚îÇ
‚îÇ  ‚Ä¢ Transforma resumos em artigos completos (800-1200 pal.)  ‚îÇ
‚îÇ  ‚Ä¢ Gera t√≠tulo SEO-friendly                                 ‚îÇ
‚îÇ  ‚Ä¢ Cria meta-description                                    ‚îÇ
‚îÇ  ‚Ä¢ Define tags relevantes                                   ‚îÇ
‚îÇ  ‚Ä¢ Mant√©m tom liter√°rio e profissional                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            BUSCA DE IMAGENS (Unsplash API)                  ‚îÇ
‚îÇ  ‚Ä¢ Busca imagens relacionadas ao tema                       ‚îÇ
‚îÇ  ‚Ä¢ Download e upload para Supabase Storage                  ‚îÇ
‚îÇ  ‚Ä¢ Adiciona como featured_image                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 SALVAMENTO NO BANCO                         ‚îÇ
‚îÇ  Status: 'pending' (aguardando modera√ß√£o)                   ‚îÇ
‚îÇ  Notifica√ß√£o para admin revisar                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MODERA√á√ÉO MANUAL (Admin)                       ‚îÇ
‚îÇ  ‚Ä¢ Revisa conte√∫do                                          ‚îÇ
‚îÇ  ‚Ä¢ Edita se necess√°rio                                      ‚îÇ
‚îÇ  ‚Ä¢ Aprova ou rejeita                                        ‚îÇ
‚îÇ  ‚Ä¢ Agenda publica√ß√£o                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PUBLICA√á√ÉO                               ‚îÇ
‚îÇ  Status: 'published'                                        ‚îÇ
‚îÇ  Dispon√≠vel no blog p√∫blico                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üíª TECNOLOGIAS UTILIZADAS

### Backend

- **Django 5.0.3** - Framework web
- **PostgreSQL (Supabase)** - Banco de dados
- **Celery** - Task queue para automa√ß√£o
- **Redis** - Message broker do Celery

### APIs de IA

| Servi√ßo | Fun√ß√£o | Custo |
|---------|--------|-------|
| **Claude API (Anthropic)** | Cria√ß√£o de artigos completos | R$ 0 (j√° inclu√≠do no plano) |
| **Gemini Pro (Google)** | Filtragem e resumo de not√≠cias | R$ 0 (plano gratuito - 60 req/min) |

### APIs de Conte√∫do

| Servi√ßo | Fun√ß√£o | Custo | Limite |
|---------|--------|-------|--------|
| **Google News RSS** | Agrega√ß√£o de not√≠cias | R$ 0 | Ilimitado |
| **PublishNews RSS** | Not√≠cias espec√≠ficas de livros | R$ 0 | Ilimitado |
| **Unsplash API** | Imagens de alta qualidade | R$ 0 | 50 req/hora |

### Storage

- **Supabase Storage** - Armazenamento de imagens

### Bibliotecas Python

```python
# requirements.txt (adicionar)
feedparser==6.0.10           # Parser de RSS feeds
google-generativeai==0.3.2   # Gemini API
anthropic==0.7.8             # Claude API (se usar SDK)
requests==2.31.0             # HTTP requests
pillow==10.1.0               # Processamento de imagens
celery==5.3.4                # Task scheduling
redis==5.0.1                 # Celery broker
python-decouple==3.8         # Vari√°veis de ambiente
```

---

## üìä ESTRUTURA DE DADOS

### Models Django

**Localiza√ß√£o:** `C:\ProjectDjango\cgbookstore_v3\news\models\`

#### 1. NewsCategory

```python
class NewsCategory(models.Model):
    """
    Categorias de not√≠cias do blog
    Ex: Lan√ßamentos, Resenhas, Entrevistas, Mercado Editorial
    """
    name = models.CharField(max_length=100, verbose_name="Nome")
    slug = models.SlugField(unique=True, verbose_name="Slug")
    description = models.TextField(blank=True, verbose_name="Descri√ß√£o")
    icon = models.CharField(max_length=50, blank=True, help_text="Classe do √≠cone Bootstrap")
    order = models.IntegerField(default=0, verbose_name="Ordem de exibi√ß√£o")
    is_active = models.BooleanField(default=True, verbose_name="Ativo")
    
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "Categoria de Not√≠cia"
        verbose_name_plural = "Categorias de Not√≠cias"
        ordering = ['order', 'name']
    
    def __str__(self):
        return self.name
```

#### 2. NewsPost

```python
class NewsPost(models.Model):
    """
    Post de not√≠cia do blog
    """
    STATUS_CHOICES = [
        ('draft', 'Rascunho'),
        ('pending', 'Aguardando Revis√£o'),
        ('published', 'Publicado'),
        ('rejected', 'Rejeitado'),
    ]
    
    # Conte√∫do principal
    title = models.CharField(max_length=200, verbose_name="T√≠tulo")
    slug = models.SlugField(unique=True, verbose_name="Slug")
    category = models.ForeignKey(
        NewsCategory, 
        on_delete=models.SET_NULL, 
        null=True,
        related_name='posts',
        verbose_name="Categoria"
    )
    
    excerpt = models.TextField(
        max_length=300, 
        verbose_name="Resumo",
        help_text="Breve descri√ß√£o para listagens e SEO"
    )
    content = models.TextField(verbose_name="Conte√∫do completo")
    
    # Imagens
    featured_image = models.URLField(
        blank=True,
        verbose_name="Imagem destacada",
        help_text="URL da imagem no Supabase Storage"
    )
    featured_image_alt = models.CharField(
        max_length=200,
        blank=True,
        verbose_name="Texto alternativo da imagem"
    )
    
    # Fonte original
    source_url = models.URLField(
        blank=True, 
        verbose_name="URL da fonte",
        help_text="Link para not√≠cia original"
    )
    source_name = models.CharField(
        max_length=100, 
        blank=True,
        verbose_name="Nome da fonte"
    )
    
    # Metadados de IA
    ai_generated = models.BooleanField(
        default=False, 
        verbose_name="Gerado por IA"
    )
    ai_model_primary = models.CharField(
        max_length=50, 
        blank=True,
        verbose_name="Modelo IA principal",
        help_text="Ex: claude-3-sonnet, gemini-pro"
    )
    ai_model_secondary = models.CharField(
        max_length=50, 
        blank=True,
        verbose_name="Modelo IA secund√°rio"
    )
    ai_processing_time = models.FloatField(
        null=True,
        blank=True,
        verbose_name="Tempo de processamento (segundos)"
    )
    
    # SEO
    tags = models.JSONField(
        default=list,
        verbose_name="Tags",
        help_text="Lista de palavras-chave"
    )
    meta_description = models.CharField(
        max_length=160,
        blank=True,
        verbose_name="Meta descri√ß√£o (SEO)"
    )
    
    # Controle de publica√ß√£o
    status = models.CharField(
        max_length=20, 
        choices=STATUS_CHOICES, 
        default='draft',
        verbose_name="Status"
    )
    author = models.ForeignKey(
        'auth.User',
        on_delete=models.SET_NULL,
        null=True,
        related_name='news_posts',
        verbose_name="Autor"
    )
    published_at = models.DateTimeField(
        null=True, 
        blank=True,
        verbose_name="Data de publica√ß√£o"
    )
    
    # M√©tricas
    views_count = models.IntegerField(
        default=0,
        verbose_name="Visualiza√ß√µes"
    )
    
    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "Post de Not√≠cia"
        verbose_name_plural = "Posts de Not√≠cias"
        ordering = ['-published_at', '-created_at']
        indexes = [
            models.Index(fields=['status', '-published_at']),
            models.Index(fields=['slug']),
            models.Index(fields=['category', 'status']),
        ]
    
    def __str__(self):
        return self.title
    
    def save(self, *args, **kwargs):
        # Auto-gerar slug se n√£o existir
        if not self.slug:
            from django.utils.text import slugify
            self.slug = slugify(self.title)
        
        # Auto-definir published_at quando publicar
        if self.status == 'published' and not self.published_at:
            from django.utils import timezone
            self.published_at = timezone.now()
        
        super().save(*args, **kwargs)
    
    @property
    def reading_time(self):
        """Calcula tempo de leitura estimado (palavras/min)"""
        words = len(self.content.split())
        minutes = max(1, words // 200)  # 200 palavras por minuto
        return minutes
```

#### 3. NewsSource

```python
class NewsSource(models.Model):
    """
    Fontes RSS para agrega√ß√£o de not√≠cias
    """
    SOURCE_TYPE_CHOICES = [
        ('rss', 'RSS Feed'),
        ('atom', 'Atom Feed'),
        ('json', 'JSON Feed'),
    ]
    
    name = models.CharField(max_length=100, verbose_name="Nome da fonte")
    url = models.URLField(unique=True, verbose_name="URL do feed")
    source_type = models.CharField(
        max_length=10,
        choices=SOURCE_TYPE_CHOICES,
        default='rss',
        verbose_name="Tipo de feed"
    )
    
    # Configura√ß√µes
    is_active = models.BooleanField(default=True, verbose_name="Ativo")
    priority = models.IntegerField(
        default=1,
        verbose_name="Prioridade",
        help_text="1-10, quanto maior mais importante"
    )
    
    # Filtros
    keywords_include = models.JSONField(
        default=list,
        blank=True,
        verbose_name="Palavras-chave (incluir)",
        help_text="Not√≠cias devem conter pelo menos uma dessas palavras"
    )
    keywords_exclude = models.JSONField(
        default=list,
        blank=True,
        verbose_name="Palavras-chave (excluir)",
        help_text="Not√≠cias com essas palavras ser√£o ignoradas"
    )
    
    # Estat√≠sticas
    last_fetch_at = models.DateTimeField(
        null=True,
        blank=True,
        verbose_name="√öltima busca"
    )
    last_fetch_status = models.CharField(
        max_length=20,
        blank=True,
        verbose_name="Status da √∫ltima busca"
    )
    total_items_fetched = models.IntegerField(
        default=0,
        verbose_name="Total de itens buscados"
    )
    total_items_published = models.IntegerField(
        default=0,
        verbose_name="Total de itens publicados"
    )
    
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "Fonte de Not√≠cias"
        verbose_name_plural = "Fontes de Not√≠cias"
        ordering = ['-priority', 'name']
    
    def __str__(self):
        return f"{self.name} ({'Ativo' if self.is_active else 'Inativo'})"
```

---

## üîß IMPLEMENTA√á√ÉO POR FASES

### FASE 1: Estrutura Base (1-2 dias)

**Objetivo:** Criar estrutura b√°sica do m√≥dulo news

#### Tarefas:

1. **Criar models**
   - [ ] `NewsCategory`
   - [ ] `NewsPost`
   - [ ] `NewsSource`
   
2. **Migrations**
   ```bash
   python manage.py makemigrations news
   python manage.py migrate
   ```

3. **Admin b√°sico**
   ```python
   # news/admin.py
   
   @admin.register(NewsPost)
   class NewsPostAdmin(admin.ModelAdmin):
       list_display = ['title', 'category', 'status', 'ai_generated', 'published_at']
       list_filter = ['status', 'category', 'ai_generated']
       search_fields = ['title', 'content']
       prepopulated_fields = {'slug': ('title',)}
   ```

4. **URLs b√°sicas**
   ```python
   # news/urls.py
   
   urlpatterns = [
       path('', NewsListView.as_view(), name='news_list'),
       path('categoria/<slug:slug>/', NewsCategoryView.as_view(), name='news_category'),
       path('<slug:slug>/', NewsDetailView.as_view(), name='news_detail'),
   ]
   ```

5. **Views b√°sicas**
   - ListView para listagem
   - DetailView para post individual
   - CategoryView para posts por categoria

6. **Templates b√°sicos**
   - `news/news_list.html`
   - `news/news_detail.html`
   - `news/partials/news_card.html`

**Commit:** `feat(news): estrutura base do m√≥dulo news`

---

### FASE 2: Servi√ßo de Agrega√ß√£o RSS (1-2 dias)

**Objetivo:** Implementar coleta de not√≠cias de feeds RSS

#### Tarefas:

1. **Criar servi√ßo de agrega√ß√£o**

```python
# news/services/rss_aggregator.py

import feedparser
from datetime import datetime, timedelta
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)

class RSSAggregator:
    """
    Servi√ßo para agregar not√≠cias de m√∫ltiplos feeds RSS
    """
    
    def __init__(self):
        self.sources = []
        self.load_active_sources()
    
    def load_active_sources(self):
        """Carrega fontes ativas do banco"""
        from news.models import NewsSource
        self.sources = NewsSource.objects.filter(is_active=True)
    
    def fetch_all_feeds(self, hours_back: int = 24) -> List[Dict]:
        """
        Busca not√≠cias de todos os feeds ativos
        
        Args:
            hours_back: Buscar not√≠cias das √∫ltimas X horas
        
        Returns:
            Lista de dicion√°rios com as not√≠cias
        """
        all_news = []
        cutoff_date = datetime.now() - timedelta(hours=hours_back)
        
        for source in self.sources:
            try:
                news_items = self.fetch_single_feed(source, cutoff_date)
                all_news.extend(news_items)
                
                # Atualizar estat√≠sticas
                source.last_fetch_at = datetime.now()
                source.last_fetch_status = 'success'
                source.total_items_fetched += len(news_items)
                source.save()
                
                logger.info(f"Fetched {len(news_items)} items from {source.name}")
                
            except Exception as e:
                logger.error(f"Error fetching {source.name}: {str(e)}")
                source.last_fetch_status = f'error: {str(e)[:50]}'
                source.save()
        
        return all_news
    
    def fetch_single_feed(self, source, cutoff_date: datetime) -> List[Dict]:
        """
        Busca not√≠cias de um √∫nico feed
        
        Args:
            source: Objeto NewsSource
            cutoff_date: Data de corte para not√≠cias antigas
        
        Returns:
            Lista de dicion√°rios com as not√≠cias
        """
        feed = feedparser.parse(source.url)
        news_items = []
        
        for entry in feed.entries:
            # Parse da data
            published_date = self._parse_entry_date(entry)
            
            # Filtrar por data
            if published_date and published_date < cutoff_date:
                continue
            
            # Extrair dados
            news_item = {
                'title': entry.get('title', ''),
                'link': entry.get('link', ''),
                'description': entry.get('description', entry.get('summary', '')),
                'published_date': published_date,
                'source_name': source.name,
                'source_url': source.url,
                'source_priority': source.priority,
            }
            
            # Aplicar filtros de palavras-chave
            if self._passes_keyword_filters(news_item, source):
                news_items.append(news_item)
        
        return news_items
    
    def _parse_entry_date(self, entry) -> datetime:
        """Parse da data do entry RSS"""
        date_fields = ['published_parsed', 'updated_parsed']
        for field in date_fields:
            if hasattr(entry, field):
                time_struct = getattr(entry, field)
                if time_struct:
                    return datetime(*time_struct[:6])
        return datetime.now()
    
    def _passes_keyword_filters(self, news_item: Dict, source) -> bool:
        """
        Verifica se a not√≠cia passa pelos filtros de palavras-chave
        """
        text = f"{news_item['title']} {news_item['description']}".lower()
        
        # Filtro de exclus√£o
        if source.keywords_exclude:
            for keyword in source.keywords_exclude:
                if keyword.lower() in text:
                    return False
        
        # Filtro de inclus√£o (se configurado)
        if source.keywords_include:
            for keyword in source.keywords_include:
                if keyword.lower() in text:
                    return True
            return False  # Nenhuma palavra-chave encontrada
        
        return True
```

2. **Criar fontes RSS padr√£o**

```python
# news/management/commands/setup_news_sources.py

from django.core.management.base import BaseCommand
from news.models import NewsSource

class Command(BaseCommand):
    help = 'Configura fontes RSS padr√£o de not√≠cias liter√°rias'
    
    def handle(self, *args, **options):
        sources = [
            {
                'name': 'Google News - Livros Literatura',
                'url': 'https://news.google.com/rss/search?q=livros+literatura+when:7d&hl=pt-BR&gl=BR&ceid=BR:pt-419',
                'priority': 10,
                'keywords_include': ['livro', 'autor', 'literatura', 'editora', 'lan√ßamento'],
            },
            {
                'name': 'Google News - Bestsellers',
                'url': 'https://news.google.com/rss/search?q=bestseller+literatura+livro&hl=pt-BR&gl=BR&ceid=BR:pt-419',
                'priority': 9,
            },
            {
                'name': 'PublishNews',
                'url': 'https://publishnews.com.br/feed',
                'priority': 10,
            },
            # Adicionar mais fontes conforme necess√°rio
        ]
        
        for source_data in sources:
            source, created = NewsSource.objects.get_or_create(
                url=source_data['url'],
                defaults=source_data
            )
            
            if created:
                self.stdout.write(self.style.SUCCESS(f'‚úì Criada: {source.name}'))
            else:
                self.stdout.write(self.style.WARNING(f'‚óã J√° existe: {source.name}'))
```

**Commit:** `feat(news): implementa agrega√ß√£o RSS`

---

### FASE 3: Integra√ß√£o com Gemini (Filtragem) (1-2 dias)

**Objetivo:** Usar Gemini para filtrar e selecionar melhores not√≠cias

#### Tarefas:

1. **Configurar vari√°veis de ambiente**

```python
# .env
GEMINI_API_KEY=sua_chave_aqui
```

2. **Criar servi√ßo Gemini**

```python
# news/services/gemini_service.py

import google.generativeai as genai
from typing import List, Dict
import json
import logging
from django.conf import settings

logger = logging.getLogger(__name__)

class GeminiNewsFilter:
    """
    Servi√ßo para filtrar not√≠cias usando Gemini
    """
    
    def __init__(self):
        genai.configure(api_key=settings.GEMINI_API_KEY)
        self.model = genai.GenerativeModel('gemini-pro')
    
    def filter_and_rank_news(
        self, 
        news_items: List[Dict], 
        limit: int = 10
    ) -> List[Dict]:
        """
        Filtra e ranqueia not√≠cias por relev√¢ncia
        
        Args:
            news_items: Lista de not√≠cias coletadas
            limit: N√∫mero de not√≠cias a retornar
        
        Returns:
            Lista das melhores not√≠cias com resumos
        """
        try:
            # Preparar prompt
            prompt = self._build_filter_prompt(news_items, limit)
            
            # Chamar Gemini
            response = self.model.generate_content(prompt)
            
            # Parse da resposta JSON
            selected_news = json.loads(response.text)
            
            logger.info(f"Gemini selected {len(selected_news)} news from {len(news_items)}")
            
            return selected_news
            
        except Exception as e:
            logger.error(f"Error filtering with Gemini: {str(e)}")
            # Fallback: retornar as mais recentes
            return sorted(news_items, key=lambda x: x['published_date'], reverse=True)[:limit]
    
    def _build_filter_prompt(self, news_items: List[Dict], limit: int) -> str:
        """Constr√≥i prompt para o Gemini"""
        
        # Formatar not√≠cias para o prompt
        news_text = "\n\n".join([
            f"ID: {i}\n"
            f"T√≠tulo: {item['title']}\n"
            f"Descri√ß√£o: {item['description'][:200]}...\n"
            f"Fonte: {item['source_name']}"
            for i, item in enumerate(news_items)
        ])
        
        prompt = f"""
Voc√™ √© um especialista em literatura e curadoria de conte√∫do para um blog liter√°rio chamado CGBookStore.

Analise as seguintes {len(news_items)} not√≠cias sobre literatura, livros e autores:

{news_text}

TAREFA:
1. Selecione as {limit} not√≠cias MAIS RELEVANTES e interessantes para leitores apaixonados por literatura
2. Priorize not√≠cias sobre:
   - Lan√ßamentos de livros importantes
   - Entrevistas com autores
   - Pr√™mios liter√°rios
   - Tend√™ncias do mercado editorial
   - Eventos liter√°rios relevantes

3. EVITE not√≠cias sobre:
   - Celebridades que n√£o s√£o autores
   - Pol√≠tica (a menos que seja sobre censura/liberdade de express√£o liter√°ria)
   - Not√≠cias muito gen√©ricas ou superficiais

Para cada not√≠cia selecionada, crie um resumo executivo em portugu√™s brasileiro (150-200 palavras).

RETORNE APENAS um JSON v√°lido neste formato:
[
  {{
    "id": 0,
    "relevance_score": 9.5,
    "summary": "Resumo executivo aqui...",
    "suggested_category": "Lan√ßamentos",
    "suggested_tags": ["tag1", "tag2", "tag3"]
  }}
]

N√ÉO inclua nenhum texto antes ou depois do JSON.
"""
        return prompt
```

**Commit:** `feat(news): integra Gemini para filtragem`

---

### FASE 4: Integra√ß√£o com Claude (Cria√ß√£o de Conte√∫do) (2-3 dias)

**Objetivo:** Usar Claude para criar artigos completos

#### Tarefas:

1. **Configurar vari√°veis de ambiente**

```python
# .env
CLAUDE_API_KEY=sua_chave_aqui  # Se usar API
# OU usar via interface (voc√™ j√° paga)
```

2. **Criar servi√ßo Claude**

```python
# news/services/claude_service.py

from anthropic import Anthropic
from typing import Dict
import logging
from django.conf import settings

logger = logging.getLogger(__name__)

class ClaudeArticleCreator:
    """
    Servi√ßo para criar artigos completos usando Claude
    """
    
    def __init__(self):
        self.client = Anthropic(api_key=settings.CLAUDE_API_KEY)
    
    def create_article(self, news_data: Dict) -> Dict:
        """
        Cria artigo completo a partir de resumo
        
        Args:
            news_data: Dict com resumo e dados da not√≠cia
        
        Returns:
            Dict com artigo completo
        """
        try:
            prompt = self._build_article_prompt(news_data)
            
            message = self.client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=4096,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            # Parse do conte√∫do
            article_data = self._parse_claude_response(message.content[0].text)
            
            logger.info(f"Claude created article: {article_data['title'][:50]}...")
            
            return article_data
            
        except Exception as e:
            logger.error(f"Error creating article with Claude: {str(e)}")
            raise
    
    def _build_article_prompt(self, news_data: Dict) -> str:
        """Constr√≥i prompt para o Claude"""
        
        prompt = f"""
Voc√™ √© um escritor especializado em literatura para o blog CGBookStore, um portal dedicado a leitores apaixonados por livros.

INFORMA√á√ïES DA NOT√çCIA:
T√≠tulo original: {news_data['title']}
Resumo: {news_data['summary']}
Fonte: {news_data['source_name']}
Link: {news_data['link']}

TAREFA:
Crie um artigo completo em portugu√™s brasileiro sobre esta not√≠cia, seguindo estas diretrizes:

ESTRUTURA:
1. T√≠tulo cativante e SEO-friendly (m√°ximo 70 caracteres)
2. Introdu√ß√£o envolvente (2-3 par√°grafos)
3. Corpo do artigo com desenvolvimento (4-6 par√°grafos)
4. Conclus√£o interessante (1-2 par√°grafos)

ESTILO:
- Tom: Profissional mas acess√≠vel, apaixonado por literatura
- Linguagem: Clara, envolvente, evitando jarg√µes excessivos
- Tamanho: 800-1200 palavras
- Foco: Valor para o leitor (por que isso importa?)

SEO:
- Use palavras-chave naturalmente
- Inclua sin√¥nimos e varia√ß√µes
- Estruture com par√°grafos curtos

IMPORTANTE:
- N√ÉO copie o texto original
- Adicione contexto e an√°lise pr√≥pria
- Mantenha fatos e informa√ß√µes precisas
- Cite a fonte original ao final

RETORNE no formato JSON:
{{
  "title": "T√≠tulo do artigo",
  "content": "Conte√∫do completo em HTML (use <p>, <h2>, <strong>, etc)",
  "excerpt": "Resumo de 200-300 caracteres",
  "meta_description": "Meta description SEO (150-160 caracteres)",
  "tags": ["tag1", "tag2", "tag3", "tag4", "tag5"]
}}
"""
        return prompt
    
    def _parse_claude_response(self, response_text: str) -> Dict:
        """Parse da resposta do Claude"""
        import json
        import re
        
        # Remover markdown se houver
        json_text = re.sub(r'```json\n?', '', response_text)
        json_text = re.sub(r'```\n?', '', json_text)
        
        # Parse JSON
        article_data = json.loads(json_text.strip())
        
        return article_data
```

**Commit:** `feat(news): integra Claude para cria√ß√£o de artigos`

---

### FASE 5: Busca de Imagens (Unsplash) (1 dia)

**Objetivo:** Buscar imagens automaticamente

#### Tarefas:

1. **Configurar Unsplash API**

```python
# .env
UNSPLASH_ACCESS_KEY=sua_chave_aqui
```

2. **Criar servi√ßo de imagens**

```python
# news/services/image_service.py

import requests
from typing import Optional
import logging
from django.conf import settings

logger = logging.getLogger(__name__)

class UnsplashImageService:
    """
    Servi√ßo para buscar imagens no Unsplash
    """
    
    BASE_URL = "https://api.unsplash.com"
    
    def __init__(self):
        self.access_key = settings.UNSPLASH_ACCESS_KEY
    
    def search_image(
        self, 
        keywords: list, 
        orientation: str = 'landscape'
    ) -> Optional[Dict]:
        """
        Busca imagem relacionada √†s palavras-chave
        
        Args:
            keywords: Lista de palavras-chave
            orientation: 'landscape', 'portrait' ou 'squarish'
        
        Returns:
            Dict com dados da imagem ou None
        """
        try:
            # Construir query
            query = ' '.join(keywords[:3])  # Usar at√© 3 keywords
            
            # Fazer requisi√ß√£o
            response = requests.get(
                f"{self.BASE_URL}/search/photos",
                params={
                    'query': query,
                    'per_page': 5,
                    'orientation': orientation,
                },
                headers={
                    'Authorization': f'Client-ID {self.access_key}'
                }
            )
            
            response.raise_for_status()
            data = response.json()
            
            if data['results']:
                # Pegar primeira imagem
                image = data['results'][0]
                
                return {
                    'url': image['urls']['regular'],
                    'download_url': image['links']['download_location'],
                    'photographer': image['user']['name'],
                    'photographer_url': image['user']['links']['html'],
                    'alt_description': image.get('alt_description', query),
                }
            
            logger.warning(f"No images found for: {query}")
            return None
            
        except Exception as e:
            logger.error(f"Error searching Unsplash: {str(e)}")
            return None
    
    def download_image(self, image_data: Dict) -> Optional[bytes]:
        """
        Faz download da imagem
        
        Returns:
            Bytes da imagem ou None
        """
        try:
            # Notificar Unsplash do download (requerido pela API)
            requests.get(
                image_data['download_url'],
                headers={'Authorization': f'Client-ID {self.access_key}'}
            )
            
            # Fazer download
            response = requests.get(image_data['url'])
            response.raise_for_status()
            
            return response.content
            
        except Exception as e:
            logger.error(f"Error downloading image: {str(e)}")
            return None
```

3. **Integrar com Supabase Storage**

```python
# news/services/storage_service.py

from supabase import create_client
from django.conf import settings
import uuid
from typing import Optional

class SupabaseStorageService:
    """
    Servi√ßo para upload de imagens no Supabase Storage
    """
    
    def __init__(self):
        self.client = create_client(
            settings.SUPABASE_URL,
            settings.SUPABASE_KEY
        )
        self.bucket = 'news-images'
    
    def upload_image(
        self, 
        image_data: bytes, 
        filename: Optional[str] = None
    ) -> Optional[str]:
        """
        Faz upload da imagem para Supabase Storage
        
        Returns:
            URL p√∫blica da imagem ou None
        """
        try:
            # Gerar nome √∫nico
            if not filename:
                filename = f"{uuid.uuid4()}.jpg"
            
            # Upload
            response = self.client.storage.from_(self.bucket).upload(
                filename,
                image_data,
                {'content-type': 'image/jpeg'}
            )
            
            # Obter URL p√∫blica
            public_url = self.client.storage.from_(self.bucket).get_public_url(filename)
            
            return public_url
            
        except Exception as e:
            logger.error(f"Error uploading to Supabase: {str(e)}")
            return None
```

**Commit:** `feat(news): implementa busca e upload de imagens`

---

### FASE 6: Management Command Principal (1-2 dias)

**Objetivo:** Criar comando Django que orquestra todo o processo

#### Tarefas:

1. **Criar comando principal**

```python
# news/management/commands/generate_news_posts.py

from django.core.management.base import BaseCommand
from django.utils import timezone
from news.models import NewsPost, NewsCategory
from news.services.rss_aggregator import RSSAggregator
from news.services.gemini_service import GeminiNewsFilter
from news.services.claude_service import ClaudeArticleCreator
from news.services.image_service import UnsplashImageService
from news.services.storage_service import SupabaseStorageService
import logging
import time

logger = logging.getLogger(__name__)

class Command(BaseCommand):
    help = 'Gera posts de not√≠cias automaticamente usando IA'
    
    def add_arguments(self, parser):
        parser.add_argument(
            '--limit',
            type=int,
            default=10,
            help='N√∫mero de posts a gerar'
        )
        parser.add_argument(
            '--hours-back',
            type=int,
            default=24,
            help='Buscar not√≠cias das √∫ltimas X horas'
        )
        parser.add_argument(
            '--dry-run',
            action='store_true',
            help='Simular sem salvar no banco'
        )
    
    def handle(self, *args, **options):
        limit = options['limit']
        hours_back = options['hours_back']
        dry_run = options['dry_run']
        
        self.stdout.write(self.style.NOTICE(f'\nü§ñ Iniciando gera√ß√£o de {limit} posts...'))
        
        start_time = time.time()
        
        try:
            # 1. AGREGA√á√ÉO
            self.stdout.write('\nüì° FASE 1: Agregando not√≠cias de RSS feeds...')
            aggregator = RSSAggregator()
            raw_news = aggregator.fetch_all_feeds(hours_back=hours_back)
            self.stdout.write(self.style.SUCCESS(f'  ‚úì {len(raw_news)} not√≠cias coletadas'))
            
            if not raw_news:
                self.stdout.write(self.style.WARNING('  ‚ö† Nenhuma not√≠cia encontrada'))
                return
            
            # 2. FILTRAGEM COM GEMINI
            self.stdout.write('\nüîç FASE 2: Filtrando com Gemini...')
            gemini_filter = GeminiNewsFilter()
            selected_news = gemini_filter.filter_and_rank_news(raw_news, limit=limit)
            self.stdout.write(self.style.SUCCESS(f'  ‚úì {len(selected_news)} not√≠cias selecionadas'))
            
            # 3. CRIA√á√ÉO COM CLAUDE
            self.stdout.write('\n‚úçÔ∏è  FASE 3: Criando artigos com Claude...')
            claude_creator = ClaudeArticleCreator()
            
            for i, news_item in enumerate(selected_news, 1):
                self.stdout.write(f'\n  [{i}/{len(selected_news)}] Processando: {news_item["title"][:50]}...')
                
                try:
                    # 3.1 Criar artigo
                    article_data = claude_creator.create_article(news_item)
                    
                    # 3.2 Buscar imagem
                    self.stdout.write('    üñºÔ∏è  Buscando imagem...')
                    image_service = UnsplashImageService()
                    image_data = image_service.search_image(article_data['tags'])
                    
                    image_url = None
                    if image_data:
                        # Download e upload
                        image_bytes = image_service.download_image(image_data)
                        if image_bytes:
                            storage = SupabaseStorageService()
                            image_url = storage.upload_image(image_bytes)
                            self.stdout.write(self.style.SUCCESS('    ‚úì Imagem adicionada'))
                    
                    # 3.3 Determinar categoria
                    category = self._get_or_create_category(
                        news_item.get('suggested_category', 'Geral')
                    )
                    
                    # 3.4 Salvar no banco
                    if not dry_run:
                        post = NewsPost.objects.create(
                            title=article_data['title'],
                            content=article_data['content'],
                            excerpt=article_data['excerpt'],
                            meta_description=article_data['meta_description'],
                            tags=article_data['tags'],
                            
                            category=category,
                            featured_image=image_url or '',
                            featured_image_alt=image_data.get('alt_description', '') if image_data else '',
                            
                            source_url=news_item['link'],
                            source_name=news_item['source_name'],
                            
                            ai_generated=True,
                            ai_model_primary='claude-3-5-sonnet',
                            ai_model_secondary='gemini-pro',
                            
                            status='pending',  # Aguardando modera√ß√£o
                        )
                        
                        self.stdout.write(self.style.SUCCESS(f'    ‚úì Post salvo (ID: {post.id})'))
                    else:
                        self.stdout.write(self.style.WARNING('    ‚óã [DRY RUN] Post n√£o salvo'))
                    
                    # Pausa para n√£o sobrecarregar APIs
                    time.sleep(2)
                    
                except Exception as e:
                    self.stdout.write(self.style.ERROR(f'    ‚úó Erro: {str(e)}'))
                    logger.error(f"Error processing news {i}: {str(e)}")
                    continue
            
            # RESUMO
            elapsed = time.time() - start_time
            self.stdout.write(self.style.SUCCESS(f'\n\n‚úÖ Processo conclu√≠do em {elapsed:.1f}s'))
            
            if not dry_run:
                pending_count = NewsPost.objects.filter(status='pending').count()
                self.stdout.write(f'üìä {pending_count} posts aguardando modera√ß√£o')
            
        except Exception as e:
            self.stdout.write(self.style.ERROR(f'\n‚ùå Erro geral: {str(e)}'))
            logger.error(f"Fatal error: {str(e)}")
    
    def _get_or_create_category(self, name: str):
        """Obt√©m ou cria categoria"""
        from django.utils.text import slugify
        category, _ = NewsCategory.objects.get_or_create(
            slug=slugify(name),
            defaults={'name': name}
        )
        return category
```

2. **Testar comando**

```bash
# Teste sem salvar
python manage.py generate_news_posts --limit 3 --dry-run

# Gera√ß√£o real
python manage.py generate_news_posts --limit 5
```

**Commit:** `feat(news): implementa comando de gera√ß√£o autom√°tica`

---

### FASE 7: Automa√ß√£o com Celery (1-2 dias)

**Objetivo:** Automatizar execu√ß√£o di√°ria

#### Tarefas:

1. **Configurar Celery**

```python
# cgbookstore/celery.py

from celery import Celery
from celery.schedules import crontab
import os

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'cgbookstore.settings')

app = Celery('cgbookstore')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()

# Configurar schedule
app.conf.beat_schedule = {
    'generate-daily-news': {
        'task': 'news.tasks.generate_daily_news',
        'schedule': crontab(hour=6, minute=0),  # Todo dia √†s 6h
        'kwargs': {'limit': 10},
    },
}
```

2. **Criar tasks**

```python
# news/tasks.py

from celery import shared_task
from django.core.management import call_command
import logging

logger = logging.getLogger(__name__)

@shared_task
def generate_daily_news(limit=10):
    """
    Task para gerar not√≠cias diariamente
    """
    try:
        logger.info(f"Starting daily news generation (limit={limit})")
        
        call_command('generate_news_posts', limit=limit, hours_back=24)
        
        logger.info("Daily news generation completed")
        
    except Exception as e:
        logger.error(f"Error in daily news generation: {str(e)}")
        raise
```

3. **Configurar no settings**

```python
# cgbookstore/settings.py

# Celery
CELERY_BROKER_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
CELERY_RESULT_BACKEND = CELERY_BROKER_URL
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'America/Sao_Paulo'
```

4. **Comandos para rodar Celery**

```bash
# Worker
celery -A cgbookstore worker -l info

# Beat (scheduler)
celery -A cgbookstore beat -l info

# Ou ambos juntos
celery -A cgbookstore worker --beat -l info
```

**Commit:** `feat(news): adiciona automa√ß√£o com Celery`

---

### FASE 8: Interface Admin e Modera√ß√£o (1 dia)

**Objetivo:** Melhorar interface admin para modera√ß√£o

#### Tarefas:

1. **Admin avan√ßado**

```python
# news/admin.py

from django.contrib import admin
from django.utils.html import format_html
from django.urls import reverse
from .models import NewsPost, NewsCategory, NewsSource

@admin.register(NewsPost)
class NewsPostAdmin(admin.ModelAdmin):
    list_display = [
        'title_link',
        'category',
        'status_badge',
        'ai_badge',
        'views_count',
        'published_at',
        'actions_column',
    ]
    list_filter = [
        'status',
        'category',
        'ai_generated',
        'published_at',
    ]
    search_fields = ['title', 'content', 'tags']
    prepopulated_fields = {'slug': ('title',)}
    
    fieldsets = (
        ('Conte√∫do', {
            'fields': ('title', 'slug', 'category', 'excerpt', 'content')
        }),
        ('M√≠dia', {
            'fields': ('featured_image', 'featured_image_alt')
        }),
        ('Fonte', {
            'fields': ('source_url', 'source_name')
        }),
        ('SEO', {
            'fields': ('tags', 'meta_description'),
            'classes': ('collapse',)
        }),
        ('Metadados IA', {
            'fields': (
                'ai_generated',
                'ai_model_primary',
                'ai_model_secondary',
                'ai_processing_time'
            ),
            'classes': ('collapse',)
        }),
        ('Publica√ß√£o', {
            'fields': ('status', 'author', 'published_at')
        }),
    )
    
    def title_link(self, obj):
        url = reverse('admin:news_newspost_change', args=[obj.id])
        return format_html('<a href="{}">{}</a>', url, obj.title[:60])
    title_link.short_description = 'T√≠tulo'
    
    def status_badge(self, obj):
        colors = {
            'draft': 'gray',
            'pending': 'orange',
            'published': 'green',
            'rejected': 'red',
        }
        return format_html(
            '<span style="color: {};">‚óè</span> {}',
            colors.get(obj.status, 'gray'),
            obj.get_status_display()
        )
    status_badge.short_description = 'Status'
    
    def ai_badge(self, obj):
        if obj.ai_generated:
            return format_html('ü§ñ IA')
        return '‚úçÔ∏è Manual'
    ai_badge.short_description = 'Origem'
    
    def actions_column(self, obj):
        if obj.status == 'pending':
            approve_url = reverse('admin:news_newspost_approve', args=[obj.id])
            reject_url = reverse('admin:news_newspost_reject', args=[obj.id])
            return format_html(
                '<a class="button" href="{}">‚úì Aprovar</a> '
                '<a class="button" href="{}">‚úó Rejeitar</a>',
                approve_url,
                reject_url
            )
        return '-'
    actions_column.short_description = 'A√ß√µes'
    
    actions = ['approve_posts', 'reject_posts', 'publish_posts']
    
    def approve_posts(self, request, queryset):
        updated = queryset.filter(status='pending').update(status='published')
        self.message_user(request, f'{updated} posts aprovados')
    approve_posts.short_description = 'Aprovar posts selecionados'
    
    def reject_posts(self, request, queryset):
        updated = queryset.filter(status='pending').update(status='rejected')
        self.message_user(request, f'{updated} posts rejeitados')
    reject_posts.short_description = 'Rejeitar posts selecionados'

@admin.register(NewsCategory)
class NewsCategoryAdmin(admin.ModelAdmin):
    list_display = ['name', 'slug', 'posts_count', 'is_active', 'order']
    prepopulated_fields = {'slug': ('name',)}
    list_editable = ['order', 'is_active']
    
    def posts_count(self, obj):
        return obj.posts.filter(status='published').count()
    posts_count.short_description = 'Posts publicados'

@admin.register(NewsSource)
class NewsSourceAdmin(admin.ModelAdmin):
    list_display = [
        'name',
        'source_type',
        'is_active',
        'priority',
        'success_rate',
        'last_fetch_at',
    ]
    list_filter = ['is_active', 'source_type']
    list_editable = ['is_active', 'priority']
    
    def success_rate(self, obj):
        if obj.total_items_fetched == 0:
            return '-'
        rate = (obj.total_items_published / obj.total_items_fetched) * 100
        return f'{rate:.1f}%'
    success_rate.short_description = 'Taxa de sucesso'
```

**Commit:** `feat(news): melhora interface admin`

---

## üìä WORKFLOW DE AUTOMA√á√ÉO

### Fluxo Di√°rio Autom√°tico

```
06:00 - Celery Beat dispara task
‚îÇ
‚îú‚îÄ> 06:00-06:02: Buscar feeds RSS (Google News + fontes)
‚îÇ   ‚îî‚îÄ> Coletar 50-100 not√≠cias das √∫ltimas 24h
‚îÇ
‚îú‚îÄ> 06:02-06:05: Filtrar com Gemini
‚îÇ   ‚îî‚îÄ> Selecionar top 10 mais relevantes
‚îÇ   ‚îî‚îÄ> Criar resumos executivos
‚îÇ
‚îú‚îÄ> 06:05-06:20: Criar artigos com Claude (10x)
‚îÇ   ‚îú‚îÄ> Para cada not√≠cia:
‚îÇ   ‚îÇ   ‚îú‚îÄ> Gerar artigo completo (800-1200 palavras)
‚îÇ   ‚îÇ   ‚îú‚îÄ> Buscar imagem (Unsplash)
‚îÇ   ‚îÇ   ‚îú‚îÄ> Upload imagem (Supabase)
‚îÇ   ‚îÇ   ‚îî‚îÄ> Salvar como 'pending'
‚îÇ   ‚îî‚îÄ> Pausa de 2s entre cada
‚îÇ
‚îî‚îÄ> 06:20: Notificar admin
    ‚îî‚îÄ> Email/Slack: "10 posts aguardam modera√ß√£o"
```

### Fluxo Manual de Modera√ß√£o

```
Admin acessa /admin/news/newspost/
‚îÇ
‚îú‚îÄ> Filtrar: status='pending'
‚îÇ
‚îú‚îÄ> Para cada post:
‚îÇ   ‚îú‚îÄ> Ler t√≠tulo e excerpt
‚îÇ   ‚îú‚îÄ> Revisar conte√∫do
‚îÇ   ‚îú‚îÄ> (Opcional) Editar
‚îÇ   ‚îú‚îÄ> Verificar imagem
‚îÇ   ‚îî‚îÄ> Decis√£o:
‚îÇ       ‚îú‚îÄ> Aprovar ‚Üí status='published'
‚îÇ       ‚îú‚îÄ> Rejeitar ‚Üí status='rejected'
‚îÇ       ‚îî‚îÄ> Deixar draft ‚Üí status='draft'
‚îÇ
‚îî‚îÄ> Posts aprovados aparecem no blog
```

---

## üí∞ CUSTOS E RECURSOS

### Breakdown de Custos

| Recurso | Plano | Limite | Custo/m√™s |
|---------|-------|--------|-----------|
| **Claude API** | Pro (existente) | Inclu√≠do no plano | R$ 0* |
| **Gemini Pro** | Free | 60 req/min, 1500/dia | R$ 0 |
| **Google News RSS** | - | Ilimitado | R$ 0 |
| **Unsplash API** | Free | 50 req/hora | R$ 0 |
| **Supabase Storage** | Free | 1GB storage | R$ 0 |
| **Redis** | Free/Self-hosted | - | R$ 0 |
| **TOTAL** | | | **R$ 0** |

*J√° inclu√≠do no plano pago existente

### Consumo Estimado (30 posts/m√™s)

- **Gemini:** ~3 chamadas/dia √ó 30 dias = 90 chamadas/m√™s ‚úÖ
- **Claude:** ~10 chamadas/dia √ó 30 dias = 300 chamadas/m√™s ‚úÖ
- **Unsplash:** ~10 imagens/dia √ó 30 dias = 300 imagens/m√™s ‚úÖ

**Todos dentro dos limites gratuitos!**

---

## üóìÔ∏è ROADMAP DE DESENVOLVIMENTO

### Sprint 1 (Semana 1-2) - MVP

- [ ] Fase 1: Estrutura base
- [ ] Fase 2: Agrega√ß√£o RSS
- [ ] Fase 3: Integra√ß√£o Gemini
- [ ] Teste manual do fluxo completo

### Sprint 2 (Semana 3-4) - Automa√ß√£o

- [ ] Fase 4: Integra√ß√£o Claude
- [ ] Fase 5: Busca de imagens
- [ ] Fase 6: Management command
- [ ] Deploy inicial

### Sprint 3 (Semana 5-6) - Produ√ß√£o

- [ ] Fase 7: Celery automa√ß√£o
- [ ] Fase 8: Interface admin
- [ ] Testes de carga
- [ ] Documenta√ß√£o final

### Melhorias Futuras (Backlog)

- [ ] Sistema de agendamento de publica√ß√µes
- [ ] Analytics de performance de posts
- [ ] A/B testing de t√≠tulos
- [ ] Integra√ß√£o com redes sociais (auto-post)
- [ ] Newsletter autom√°tica
- [ ] Recomenda√ß√£o de livros relacionados
- [ ] Coment√°rios e engajamento
- [ ] API p√∫blica do blog

---

## üîß MANUTEN√á√ÉO E MONITORAMENTO

### M√©tricas a Acompanhar

1. **Performance de Agrega√ß√£o**
   - N√∫mero de not√≠cias coletadas/dia
   - Taxa de sucesso por fonte RSS
   - Tempo m√©dio de coleta

2. **Qualidade da IA**
   - Taxa de aprova√ß√£o de posts (pending ‚Üí published)
   - Taxa de rejei√ß√£o
   - Tempo m√©dio de modera√ß√£o

3. **Performance de Publica√ß√£o**
   - Posts publicados/semana
   - Visualiza√ß√µes por post
   - Taxa de engajamento

4. **Custos de API**
   - Chamadas Claude/m√™s (monitor dentro do limite)
   - Chamadas Gemini/m√™s
   - Downloads Unsplash/m√™s
   - Storage Supabase usado

### Logs Importantes

```python
# Configurar logging detalhado
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'file_news': {
            'level': 'INFO',
            'class': 'logging.FileHandler',
            'filename': 'logs/news_generation.log',
        },
    },
    'loggers': {
        'news': {
            'handlers': ['file_news'],
            'level': 'INFO',
            'propagate': False,
        },
    },
}
```

### Alertas Recomendados

- ‚ö†Ô∏è Taxa de erro > 20% na agrega√ß√£o
- ‚ö†Ô∏è Nenhum post gerado por 24h
- ‚ö†Ô∏è Fila de modera√ß√£o > 50 posts
- ‚ö†Ô∏è Erros 500 nas APIs
- ‚ö†Ô∏è Storage > 80% do limite

---

## üìû CONTATOS E REFER√äNCIAS

### Documenta√ß√µes

- **Claude API:** https://docs.anthropic.com/
- **Gemini API:** https://ai.google.dev/docs
- **Unsplash API:** https://unsplash.com/documentation
- **Feedparser:** https://feedparser.readthedocs.io/
- **Celery:** https://docs.celeryproject.org/

### Fontes RSS Liter√°rias

- Google News Literatura: `https://news.google.com/rss/search?q=literatura`
- PublishNews: `https://publishnews.com.br/feed`
- (Adicionar mais conforme descobrir)

---

## üìù NOTAS FINAIS

### Pontos de Aten√ß√£o

1. **Modera√ß√£o √© essencial** - Mesmo com IA, revisar antes de publicar
2. **Cita√ß√£o de fontes** - Sempre incluir link para not√≠cia original
3. **Originalidade** - IA deve reescrever, n√£o copiar
4. **SEO** - Focar em conte√∫do de qualidade, n√£o apenas quantidade
5. **Escalabilidade** - Come√ßar com 10 posts/dia, ajustar conforme necess√°rio

### Pr√≥ximos Passos Imediatos

1. ‚úÖ Aprovar este planejamento
2. ‚è≠Ô∏è Iniciar Fase 1 (estrutura base)
3. ‚è≠Ô∏è Configurar APIs (Gemini, Unsplash)
4. ‚è≠Ô∏è Testar fluxo manualmente
5. ‚è≠Ô∏è Implementar automa√ß√£o

---

**Documento gerado em:** 18/12/2024  
**√öltima atualiza√ß√£o:** 18/12/2024  
**Vers√£o:** 1.0  
**Status:** üìã Planejamento aprovado, aguardando implementa√ß√£o

---

