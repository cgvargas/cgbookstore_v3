"""
Servi√ßo de integra√ß√£o com Groq AI para o Chatbot Liter√°rio.
Alternativa r√°pida e gratuita ao Google Gemini.
"""
import logging
from typing import Optional, Dict, List
from django.conf import settings
from groq import Groq

logger = logging.getLogger(__name__)


class GroqChatbotService:
    """
    Servi√ßo para gerenciar conversas com o Groq AI.

    Caracter√≠sticas:
    - Foco em literatura, livros e cultura da leitura
    - Respostas objetivas mas com emo√ß√£o
    - Manuten√ß√£o de contexto da conversa
    - Tratamento de assuntos fora do escopo
    - Extremamente r√°pido (infer√™ncia em hardware especializado)
    """

    # Prompt do sistema - Define a personalidade e escopo do chatbot
    SYSTEM_PROMPT = """Voc√™ √© o Assistente Liter√°rio da CG.BookStore.

REGRAS ABSOLUTAS (SIGA RIGOROSAMENTE):

1. SEMPRE use o nome do usu√°rio em TODAS as respostas
2. CG.BookStore √© COMUNIDADE/APLICA√á√ÉO WEB - N√ÉO vendemos livros
3. Indique Amazon como parceiro para compras
4. Seja CONCISO - m√°ximo 2-3 frases por t√≥pico
5. Sempre recomende 3 T√çTULOS ESPEC√çFICOS, nunca categorias gen√©ricas
6. Usu√°rio est√° DENTRO da aplica√ß√£o - busca √© "lupa ali em cima"
7. Nosso "cat√°logo" = banco de DADOS de informa√ß√µes (n√£o vendas)

O QUE √â CG.BOOKSTORE:
- Comunidade de leitores
- Organiza√ß√£o de estantes pessoais (Quero Ler, Lendo, Lidos)
- Banco de dados com informa√ß√µes sobre livros
- Entrevistas, v√≠deos, eventos liter√°rios
- M√©dia de pre√ßos do mercado
- Indica√ß√£o de parceiros (Amazon)

VOCABUL√ÅRIO PROIBIDO:
‚ùå "vendemos livros", "nosso estoque", "dispon√≠vel aqui", "acesse o site"

VOCABUL√ÅRIO CORRETO:
‚úÖ "indicamos Amazon", "banco de dados", "lupa ali em cima", "voc√™ est√° na aplica√ß√£o"

EXEMPLO DE RESPOSTA:
Usu√°rio: "Me recomende fic√ß√£o cient√≠fica"
Voc√™: "[Nome], aqui v√£o 3 t√≠tulos:
1. **Neuromancer** (Gibson) - Cyberpunk cl√°ssico
2. **Problema dos Tr√™s Corpos** (Cixin) - Sci-fi hard
3. **M√£o Esquerda da Escurid√£o** (Le Guin) - Quest√µes sociais
Qual te interessa mais?"

ONDE COMPRAR:
"[Nome], CG.BookStore √© comunidade, n√£o vendemos. Indicamos **Amazon**:
üì¶ Onde: Amazon
üí∞ M√©dia: R$ XX-XX*
*Valores aproximados"

ESCOPO:
‚úÖ Literatura, livros, autores, g√™neros, recomenda√ß√µes
‚úÖ Adapta√ß√µes (filmes, s√©ries, anime, games, quadrinhos)
‚úÖ Tecnologia liter√°ria (e-books, audiobooks)
‚úÖ Funcionalidades da plataforma

‚ùå Assuntos fora de literatura: redirecione gentilmente"""

    def __init__(self):
        """Inicializa o servi√ßo do chatbot com Groq."""
        self.api_key = getattr(settings, 'GROQ_API_KEY', None)
        # Modelos dispon√≠veis no Groq (gratuitos):
        # - llama-3.3-70b-versatile (recomendado - mais inteligente, substitui 3.1)
        # - llama3-70b-8192 (alternativa robusta)
        # - llama-3.1-8b-instant (mais r√°pido)
        # - mixtral-8x7b-32768 (√≥timo para contextos longos)
        # - gemma2-9b-it (eficiente e r√°pido)
        self.model_name = 'llama-3.3-70b-versatile'
        self._client = None

        # Configura√ß√µes de gera√ß√£o
        self.generation_config = {
            "temperature": 0.3,  # Baixa temperatura = mais obediente √†s regras
            "max_tokens": 1024,  # Limite de tokens na resposta
            "top_p": 0.8,  # Nucleus sampling
        }

        logger.info(f"Inicializando servi√ßo do chatbot liter√°rio com Groq ({self.model_name})...")

    @property
    def client(self):
        """Lazy loading do cliente Groq."""
        if self._client is None:
            if not self.api_key:
                raise ValueError("GROQ_API_KEY n√£o configurada nas vari√°veis de ambiente")

            logger.info("Groq client loaded successfully for chatbot")
            self._client = Groq(api_key=self.api_key)
            logger.info(f"Cliente Groq para chatbot inicializado com sucesso ({self.model_name})")

        return self._client

    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel."""
        try:
            _ = self.client
            return True
        except Exception as e:
            logger.error(f"Servi√ßo Groq indispon√≠vel: {e}")
            return False

    def get_response(
        self,
        message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """
        Gera uma resposta do chatbot para a mensagem do usu√°rio.

        Args:
            message: Mensagem do usu√°rio
            conversation_history: Lista de mensagens anteriores no formato:
                [{"role": "user", "content": "mensagem"}, {"role": "assistant", "content": "resposta"}]

        Returns:
            Resposta do chatbot

        Raises:
            Exception: Se houver erro na comunica√ß√£o com a API
        """
        try:
            logger.info(f"Enviando mensagem ao Groq: {message[:100]}...")

            # Preparar mensagens para a API
            messages = [{"role": "system", "content": self.SYSTEM_PROMPT}]

            # Adicionar hist√≥rico se fornecido
            if conversation_history:
                messages.extend(conversation_history)

            # Adicionar mensagem atual do usu√°rio
            messages.append({"role": "user", "content": message})

            # Fazer chamada √† API Groq
            chat_completion = self.client.chat.completions.create(
                messages=messages,
                model=self.model_name,
                **self.generation_config
            )

            # Extrair resposta
            bot_response = chat_completion.choices[0].message.content.strip()

            # Verificar finish_reason
            finish_reason = chat_completion.choices[0].finish_reason
            logger.info(f"Groq finish reason: {finish_reason}")

            # finish_reason pode ser: "stop", "length", "content_filter", etc.

            if finish_reason == "stop":
                logger.info(f"Resposta Groq recebida com sucesso ({len(bot_response)} chars)")
                return bot_response

            elif finish_reason == "length":
                logger.warning("Resposta Groq atingiu limite de tokens")
                return bot_response + "\n\n[Resposta foi cortada por limite de tamanho. Pe√ßa para continuar!]"

            elif finish_reason == "content_filter":
                logger.warning("Resposta Groq bloqueada por filtros de conte√∫do")
                return ("Ops! Parece que sua pergunta acionou os filtros de seguran√ßa. üîí "
                       "Vamos manter nossa conversa focada em literatura e livros? "
                       "Posso te ajudar com recomenda√ß√µes, an√°lises liter√°rias ou d√∫vidas sobre o CG.BookStore! üìö‚ú®")

            else:
                logger.warning(f"Groq finish_reason inesperado: {finish_reason}")
                if bot_response:
                    return bot_response
                else:
                    return ("Hmm, algo inesperado aconteceu. ü§î "
                           "Pode tentar perguntar de outra forma? Estou aqui para ajudar! üí¨")

        except Exception as e:
            logger.error(f"Erro ao gerar resposta com Groq: {e}")
            raise Exception(f"Erro ao processar mensagem com Groq: {e}")

    def format_history_for_groq(
        self,
        messages: List[Dict[str, str]]
    ) -> List[Dict[str, str]]:
        """
        Formata hist√≥rico de mensagens para o formato esperado pelo Groq.

        Args:
            messages: Lista de mensagens no formato:
                [{"role": "user", "content": "msg"}, {"role": "assistant", "content": "resp"}]

        Returns:
            Lista no mesmo formato (Groq usa formato OpenAI compat√≠vel)
        """
        # Groq usa o mesmo formato que OpenAI, ent√£o n√£o precisa convers√£o
        return messages


# Inst√¢ncia singleton do servi√ßo
_groq_chatbot_service = None


def get_groq_chatbot_service() -> GroqChatbotService:
    """Retorna a inst√¢ncia singleton do servi√ßo de chatbot Groq."""
    global _groq_chatbot_service
    if _groq_chatbot_service is None:
        _groq_chatbot_service = GroqChatbotService()
    return _groq_chatbot_service
