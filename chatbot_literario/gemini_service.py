"""
Servi√ßo de integra√ß√£o com Google Gemini para o Chatbot Liter√°rio.
Gerencia conversas, contexto e respostas da IA.

ATUALIZADO: Integrado com RAG (Retrieval-Augmented Generation) para reduzir alucina√ß√µes.
"""
import logging
import re
from typing import Optional, Dict, List
from django.conf import settings
import google.generativeai as genai
from .knowledge_retrieval import get_knowledge_retrieval_service

logger = logging.getLogger(__name__)


class GeminiChatbotService:
    """
    Servi√ßo para gerenciar conversas com o Google Gemini AI.

    Caracter√≠sticas:
    - Foco em literatura, livros e cultura da leitura
    - Respostas objetivas mas com emo√ß√£o
    - Manuten√ß√£o de contexto da conversa
    - Tratamento de assuntos fora do escopo
    - Integra√ß√£o com RAG para reduzir alucina√ß√µes
    """

    # Prompt do sistema - Define a personalidade e escopo do chatbot
    SYSTEM_PROMPT = """Voc√™ √© o Assistente Liter√°rio da CG.BookStore.

PERSONALIDADE:
- Conversacional e prestativo
- Responde diretamente √†s perguntas
- S√≥ menciona funcionalidades quando REALMENTE relevante
- NUNCA force redirecionamentos
- HONESTO: Admite quando n√£o tem certeza

REGRAS ABSOLUTAS:

1. Use o nome do usu√°rio APENAS na primeira sauda√ß√£o
2. CG.BookStore √© COMUNIDADE - N√ÉO vendemos livros
3. Indique Amazon apenas quando perguntarem ONDE COMPRAR
4. Seja CONCISO - m√°ximo 2-3 frases por t√≥pico
5. Usu√°rio est√° DENTRO da aplica√ß√£o - busca √© "lupa ali em cima"

‚ö†Ô∏è REGRAS ANTI-ALUCINA√á√ÉO:

6. Se voc√™ receber [DADOS VERIFICADOS], priorize essas informa√ß√µes
7. Voc√™ PODE responder sobre livros e autores que voc√™ REALMENTE conhece (bestsellers, cl√°ssicos, obras famosas)
8. NUNCA INVENTE:
   - T√≠tulos de livros que N√ÉO existem
   - Nomes de autores fict√≠cios
   - Detalhes espec√≠ficos que voc√™ n√£o tem certeza (datas exatas, n√∫meros)
   - Sequ√™ncias ou livros de franquias que podem n√£o existir

9. FRANQUIAS DE JOGOS/FILMES (Diablo, Assassin's Creed, etc.):
   - N√ÉO invente livros baseados nessas franquias
   - Se perguntar sobre adapta√ß√µes liter√°rias, diga: "N√£o tenho informa√ß√µes verificadas sobre livros dessa franquia"

‚ö†Ô∏è REGRAS DE AJUDA (IMPORTANTE):

10. NUNCA OFERE√áA AJUDA QUE VOC√ä N√ÉO PODE DAR:
    - Se voc√™ n√£o tem a informa√ß√£o na sua base, N√ÉO diga "posso ajudar a buscar"
    - Se o usu√°rio pedir mais detalhes que voc√™ n√£o tem, seja honesto e conclusivo
    - N√ÉO fique em loop oferecendo ajuda gen√©rica

11. QUANDO VOC√ä CONSEGUIR RESPONDER: Responda normalmente e finalize!
    - Se voc√™ SABE a resposta (bio, autor, sinopse), d√™ a resposta completa e ponto final
    - N√ÉO adicione sugest√µes desnecess√°rias se a resposta est√° completa
    - Exemplo: "Quem √© o autor?" ‚Üí "Raphael Montes √© um escritor brasileiro de suspense..." (FIM - n√£o precisa sugerir Skoob)

12. QUANDO N√ÉO CONSEGUIR RESPONDER COMPLETAMENTE:
    - Se o usu√°rio pedir algo que voc√™ N√ÉO TEM (lista completa, dados espec√≠ficos), a√≠ sim sugira recursos externos
    - Exemplo: "Me d√™ TODOS os t√≠tulos do autor" ‚Üí Liste os que conhece + sugira Skoob para lista completa

13. QUANDO O USU√ÅRIO PEDIR AJUDA GEN√âRICA (ap√≥s voc√™ j√° ter respondido):
    - Se voc√™ j√° deu as informa√ß√µes que tinha, sugira recursos externos como resposta final
    - Exemplo: "Me ajude por favor" ‚Üí Sugira Skoob, Goodreads, Amazon

EXEMPLOS:

‚úÖ CORRETO (voc√™ sabe a resposta - finalize naturalmente):
"Quem escreveu Quarta Asa?" ‚Üí "**Quarta Asa** foi escrito por **Rebecca Yarros**. √â um romance de fantasia muito popular!"
"Me apresente a bio do autor" ‚Üí "Raphael Montes √© um escritor brasileiro de suspense e mist√©rio. Nasceu em 1990 no Rio de Janeiro..."
(N√ÉO precisa adicionar "consulte o Skoob para mais" se voc√™ respondeu bem!)

‚úÖ CORRETO (voc√™ N√ÉO tem a informa√ß√£o completa):
"Me apresente TODOS os t√≠tulos do autor!"
‚Üí "De **Raphael Montes**, conhe√ßo: **Jantar Secreto**, **Dias Perfeitos** e **O Financiador**. Para a bibliografia completa, consulte o Skoob ou Amazon."

‚úÖ CORRETO (pedido de ajuda gen√©rico - resposta final):
"Me ajude por favor!"
‚Üí "Para mais informa√ß√µes sobre esse autor:
üìö **Skoob** (skoob.com.br) - maior rede de leitores do Brasil
üìö **Goodreads** - biografias e listas completas
üìö **Amazon** - p√°gina do autor
Ou use a üîç lupa aqui em cima!"

‚ùå ERRADO (promessa vazia):
"N√£o tenho certeza, mas posso ajudar a buscar mais informa√ß√µes" ‚Üí NUNCA FA√áA ISSO

‚ùå ERRADO (inventar):
"A franquia tem livros como Diablo: A Sinister Plot..." ‚Üí NUNCA FA√áA ISSO

ONDE COMPRAR (apenas quando perguntado):
"Indicamos **Amazon** para compra:
üì¶ Onde: Amazon
üí∞ M√©dia: R$ XX-XX*"

ESCOPO:
‚úÖ Literatura, livros, autores, g√™neros, recomenda√ß√µes
‚úÖ Conhecimento geral sobre livros famosos
‚úÖ Funcionalidades da plataforma

14. SOBRE BUSCA NA INTERNET:
    - Voc√™ N√ÉO tem capacidade de acessar a internet em tempo real
    - Se perguntarem se voc√™ pode pesquisar na internet, seja HONESTO:
    ‚úÖ DIGA: "N√£o consigo acessar a internet em tempo real, mas posso te dizer o que sei! 
             Para not√≠cias recentes, recomendo:
             üì∞ Consultar nossa se√ß√£o de Not√≠cias
             üîç Pesquisar no Google por '[termo]'
             üìö Verificar no Skoob ou Goodreads"
    - NUNCA diga que vai buscar na internet se voc√™ n√£o pode

‚ùå Assuntos fora de literatura: redirecione gentilmente"""

    def __init__(self):
        """Inicializa o servi√ßo do chatbot."""
        self.api_key = settings.GEMINI_API_KEY
        self.model_name = 'models/gemini-flash-latest'  # Modelo testado e funcionando
        self._model = None

        # Configura√ß√µes de seguran√ßa mais permissivas para conte√∫do liter√°rio
        self.safety_settings = [
            {
                "category": "HARM_CATEGORY_HARASSMENT",
                "threshold": "BLOCK_NONE"  # Livros podem conter debates intensos
            },
            {
                "category": "HARM_CATEGORY_HATE_SPEECH",
                "threshold": "BLOCK_ONLY_HIGH"  # An√°lise liter√°ria pode discutir temas sens√≠veis
            },
            {
                "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                "threshold": "BLOCK_ONLY_HIGH"  # Literatura pode conter romance/intimidade
            },
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_ONLY_HIGH"  # Livros de suspense/terror existem
            },
        ]

        # Configura√ß√µes de gera√ß√£o - temperatura baixa para menos alucina√ß√µes
        self.generation_config = {
            "temperature": 0.2,  # Reduzido de 0.3 para 0.2 - mais determin√≠stico
            "top_p": 0.7,  # Reduzido de 0.8 para 0.7 - respostas mais focadas
            "top_k": 15,  # Reduzido de 20 para 15 - maior consist√™ncia
            "max_output_tokens": 1024,  # Limite para for√ßar concis√£o
        }

        # RAG - Knowledge Retrieval Service
        self.knowledge_service = get_knowledge_retrieval_service()

        logger.info(f"gemini_service: Inicializando servi√ßo do chatbot liter√°rio com RAG ({self.model_name})...")

    @property
    def model(self):
        """Lazy loading do modelo Gemini."""
        if self._model is None:
            if not self.api_key:
                raise ValueError("GEMINI_API_KEY n√£o configurada nas vari√°veis de ambiente")

            logger.info("gemini_service: google.generativeai loaded successfully for chatbot")
            genai.configure(api_key=self.api_key)

            logger.info(f"gemini_service: Inicializando modelo Gemini para chatbot ({self.model_name})...")
            self._model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings,
                system_instruction=self.SYSTEM_PROMPT
            )
            logger.info("gemini_service: Modelo Gemini para chatbot inicializado com sucesso")

        return self._model

    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel."""
        try:
            _ = self.model
            return True
        except Exception as e:
            logger.error(f"gemini_service: Servi√ßo indispon√≠vel: {e}")
            return False

    def _detect_rag_intent(self, message: str) -> Dict[str, any]:
        """
        Detecta se a mensagem requer busca de conhecimento (RAG) e qual tipo.

        Args:
            message: Mensagem do usu√°rio

        Returns:
            Dicion√°rio com intent_type e params
        """
        message_lower = message.lower()

        # Padr√µes de inten√ß√£o
        patterns = {
            'book_recommendation': r'(recomend|indic|sugir|sugest).*(livro|t√≠tulo|leitura)',
            'book_detail': r'(fale|conte|explique|detalhe|mais sobre).*(livro|t√≠tulo)',
            'book_reference': r'(livro [0-9]|t√≠tulo [0-9]|[0-9]¬∫ livro|terceiro livro)',
            'author_query': r'(quero saber quem|quem escreveu|quem √© o autor|autor d[eo]|escrito por|gostaria de saber quem)',
            'author_search': r'(livros? d[eo]|obras? d[eo]).*(autor|escritor)',
            'series_info': r'(s√©rie|saga|cole√ß√£o|cr√¥nicas|trilogia)',
            'category_search': r'(fic√ß√£o|romance|fantasia|terror|suspense|policial|biografia)',
            'adaptation_info': r'(adapta√ß√£o|adapta√ß|filme|s√©rie|netflix|hbo|amazon prime|disney)',
            'franchise_info': r'(franquia|universo|mundo de)',
        }

        for intent, pattern in patterns.items():
            if re.search(pattern, message_lower):
                logger.info(f"gemini_service RAG Intent detectado: {intent}")
                return {'intent_type': intent, 'message': message}

        # Sem inten√ß√£o RAG detectada
        return {'intent_type': None, 'message': message}

    def _apply_rag_knowledge(self, message: str, rag_intent: Dict[str, any]) -> str:
        """
        Aplica conhecimento verificado (RAG + Knowledge Base) √† mensagem antes de enviar √† IA.

        Args:
            message: Mensagem original do usu√°rio
            rag_intent: Inten√ß√£o detectada pelo _detect_rag_intent

        Returns:
            Mensagem enriquecida com dados verificados
        """
        try:
            # === CAMADA 1: KNOWLEDGE BASE (Prioridade M√°xima) ===
            from .knowledge_base_service import get_knowledge_service

            kb_service = get_knowledge_service()
            learned_knowledge = kb_service.search_knowledge(
                question=message,
                knowledge_type=rag_intent.get('intent_type'),
                min_confidence=0.7
            )

            if learned_knowledge:
                logger.info(
                    f"üß† KNOWLEDGE BASE: Usando conhecimento pr√©vio "
                    f"(ID: {learned_knowledge['id']}, usado {learned_knowledge['times_used']}x)"
                )

                enriched_prompt = f"""{message}

[CONHECIMENTO VERIFICADO - CORRE√á√ÉO ADMINISTRATIVA]
{learned_knowledge['response']}
[/CONHECIMENTO VERIFICADO]

‚ö†Ô∏è IMPORTANTE: Esta resposta foi corrigida e verificada por um administrador.
Use EXATAMENTE esta informa√ß√£o. N√ÉO invente ou adicione detalhes."""

                return enriched_prompt

            logger.info(f"‚ÑπÔ∏è Knowledge Base: Sem conhecimento pr√©vio. Usando RAG normal.")

        except Exception as e:
            logger.error(f"Erro ao consultar Knowledge Base: {e}", exc_info=True)

        # === CAMADA 1.5: FAQ DA PLATAFORMA ===
        try:
            from .faq_service import get_faq_service
            
            faq_service = get_faq_service()
            faq_context = faq_service.get_faq_context(message)
            
            if faq_context:
                logger.info(f"üìã FAQ: Encontrada resposta relevante para pergunta sobre a plataforma")
                
                enriched_prompt = f"""{message}

{faq_context}

‚ö†Ô∏è Use as informa√ß√µes do FAQ acima para responder de forma natural e amig√°vel.
Se o FAQ responder completamente, N√ÉO adicione informa√ß√µes extras."""
                
                return enriched_prompt
            
        except Exception as e:
            logger.error(f"Erro ao consultar FAQ: {e}", exc_info=True)

        # === CAMADA 2: RAG NORMAL ===
        intent_type = rag_intent.get('intent_type')

        if not intent_type:
            return message

        try:
            # INTENT 1: Recomenda√ß√£o por categoria
            if intent_type == 'book_recommendation':
                categories = ['fic√ß√£o cient√≠fica', 'romance', 'fantasia', 'terror', 'suspense', 'policial']
                for category in categories:
                    if category in message.lower():
                        logger.info(f"Buscando livros da categoria: {category}")
                        books = self.knowledge_service.search_books_by_category(category, limit=5)
                        if books:
                            verified_data = self.knowledge_service.format_multiple_books_for_prompt(books, max_books=3)
                            return f"{message}\n\n{verified_data}"

            # INTENT 2: Detalhes de um livro espec√≠fico
            elif intent_type == 'book_detail':
                words = message.split()
                if 'sobre' in message.lower():
                    idx = words.index('sobre') if 'sobre' in words else -1
                    if idx != -1 and idx + 1 < len(words):
                        book_title = ' '.join(words[idx+1:])
                        logger.info(f"Buscando livro: {book_title}")
                        book = self.knowledge_service.get_book_by_exact_title(book_title)
                        if book:
                            verified_data = self.knowledge_service.format_book_for_prompt(book)
                            return f"{message}\n\n{verified_data}"

            # INTENT 3: Query sobre autor de um livro espec√≠fico
            elif intent_type == 'author_query':
                query_words = [
                    'gostaria de saber quem escreveu o livro',
                    'gostaria de saber quem escreveu',
                    'quero saber quem escreveu o livro',
                    'quero saber quem escreveu',
                    'quem √© o autor do livro',
                    'quem √© o autor de',
                    'quem √© o autor do',
                    'quem √© o autor',
                    'quem escreveu o livro',
                    'quem escreveu',
                    'autor do livro',
                    'autor de',
                    'autor do',
                    'escrito por',
                    ', quem escreveu',
                    'o livro',
                    'livro'
                ]

                book_title = message.lower()

                for query_word in query_words:
                    if query_word in book_title:
                        book_title = book_title.replace(query_word, '', 1)
                        break

                book_title = book_title.replace('?', '').replace('!', '').replace('.', '').replace(',', '').replace(';', '').replace(':', '').strip()

                articles = ['e o ', 'e a ', 'e os ', 'e as ', 'o ', 'a ', 'os ', 'as ', 'um ', 'uma ', 'de ', 'da ', 'do ']
                for article in articles:
                    if book_title.startswith(article):
                        book_title = book_title[len(article):].strip()

                if book_title.startswith('livro '):
                    book_title = book_title[6:].strip()

                if book_title and len(book_title) > 2:
                    logger.info(f"Buscando autor do livro: '{book_title}'")

                    book = self.knowledge_service.get_book_by_exact_title(book_title)

                    if not book:
                        books = self.knowledge_service.search_books_by_title(book_title, limit=1)
                        book = books[0] if books else None

                    if book:
                        verified_data = self.knowledge_service.format_book_for_prompt(book)
                        enriched_message = f"{message}\n\n{verified_data}"
                        logger.info(f"‚úÖ RAG: Livro '{book_title}' encontrado! Autor: {book.get('author_name', 'N/A')}")
                        return enriched_message
                    else:
                        logger.warning(f"‚ö†Ô∏è RAG: Livro '{book_title}' N√ÉO encontrado no banco de dados")
                        return message

            # INTENT 4: Livros de um autor
            elif intent_type == 'author_search':
                words = message.split()
                if 'do' in words or 'de' in words:
                    idx = words.index('do') if 'do' in words else words.index('de')
                    if idx + 1 < len(words):
                        author_name = ' '.join(words[idx+1:])
                        logger.info(f"Buscando livros do autor: {author_name}")
                        books = self.knowledge_service.search_books_by_author(author_name, limit=10)
                        if books:
                            verified_data = self.knowledge_service.format_multiple_books_for_prompt(books, max_books=5)
                            return f"{message}\n\n{verified_data}"

            # INTENT 5: Informa√ß√µes sobre s√©rie
            elif intent_type == 'series_info':
                series_keywords = {
                    'n√°rnia': 'N√°rnia', 'narnia': 'N√°rnia',
                    'harry potter': 'Harry Potter',
                    'senhor dos an√©is': 'Senhor dos An√©is',
                    'hobbit': 'Hobbit',
                    'game of thrones': 'Game of Thrones',
                    'percy jackson': 'Percy Jackson',
                    'divergente': 'Divergente',
                    'jogos vorazes': 'Jogos Vorazes',
                    'dune': 'Dune',
                    'funda√ß√£o': 'Funda√ß√£o',
                }

                message_lower = message.lower()
                for keyword, series_name in series_keywords.items():
                    if keyword in message_lower:
                        logger.info(f"Buscando s√©rie: {series_name}")
                        books = self.knowledge_service.get_books_by_series_detection(keyword)
                        if books:
                            verified_data = self.knowledge_service.format_multiple_books_for_prompt(books, max_books=7)
                            return f"{message}\n\n{verified_data}"

            # INTENT 6: Busca por categoria geral
            elif intent_type == 'category_search':
                categories = {
                    'fic√ß√£o': 'Fic√ß√£o',
                    'romance': 'Romance',
                    'fantasia': 'Fantasia',
                    'terror': 'Terror',
                    'suspense': 'Suspense',
                    'policial': 'Policial',
                    'biografia': 'Biografia'
                }
                for keyword, category in categories.items():
                    if keyword in message.lower():
                        logger.info(f"Buscando categoria: {category}")
                        books = self.knowledge_service.search_books_by_category(category, limit=5)
                        if books:
                            verified_data = self.knowledge_service.format_multiple_books_for_prompt(books, max_books=3)
                            return f"{message}\n\n{verified_data}"

            # INTENT 7: Adapta√ß√µes e franquias - buscar not√≠cias primeiro
            elif intent_type in ['adaptation_info', 'franchise_info']:
                logger.info(f"Intent '{intent_type}' detectado - buscando not√≠cias relevantes")
                
                # Extrair termo de busca da mensagem
                search_terms = []
                message_lower = message.lower()
                
                # Palavras-chave comuns para extrair o assunto
                for word in ['diablo', 'witcher', 'harry potter', 'senhor dos an√©is', 'game of thrones', 
                             'percy jackson', 'hunger games', 'divergente', 'maze runner']:
                    if word in message_lower:
                        search_terms.append(word)
                
                # Se n√£o encontrou termo espec√≠fico, usar palavras-chave da mensagem
                if not search_terms:
                    # Remover stopwords e pegar principais termos
                    stopwords = ['o', 'a', 'os', 'as', 'sobre', 'que', 'voc√™', 'tem', 'de', 'da', 'do', 'informa√ß√£o', 'informa√ß√µes', 'franquia', 'adapta√ß√£o']
                    words = [w for w in message_lower.split() if w not in stopwords and len(w) > 3]
                    search_terms = words[:2]  # Pegar at√© 2 termos
                
                # Buscar not√≠cias
                for term in search_terms:
                    articles = self.knowledge_service.search_news_articles(term, limit=3)
                    if articles:
                        news_data = self.knowledge_service.format_news_for_prompt(articles)
                        logger.info(f"‚úÖ Encontradas {len(articles)} not√≠cias sobre '{term}'")
                        return f"{message}\n\n{news_data}"
                
                logger.info(f"‚ö†Ô∏è Nenhuma not√≠cia encontrada para: {search_terms}")

        except Exception as e:
            logger.error(f"Erro ao aplicar RAG knowledge: {e}", exc_info=True)

        return message

    def get_response(
        self,
        message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """
        Gera uma resposta do chatbot para a mensagem do usu√°rio.

        INTEGRADO COM RAG: Busca dados verificados no banco antes de gerar resposta.

        Args:
            message: Mensagem do usu√°rio
            conversation_history: Lista de mensagens anteriores no formato:
                [{"role": "user", "parts": ["mensagem"]}, {"role": "model", "parts": ["resposta"]}]

        Returns:
            Resposta do chatbot

        Raises:
            Exception: Se houver erro na comunica√ß√£o com a API
        """
        try:
            logger.info(f"gemini_service: Enviando mensagem ao Gemini: {message[:100]}...")

            # === RAG STEP 1: Detectar inten√ß√£o ===
            rag_intent = self._detect_rag_intent(message)

            # === RAG STEP 2: Buscar conhecimento verificado ===
            enriched_message = self._apply_rag_knowledge(message, rag_intent)

            # Verificar se o RAG encontrou dados locais
            rag_found_data = enriched_message != message
            
            if rag_found_data:
                logger.info("‚úÖ RAG ativado: Mensagem enriquecida com dados verificados do banco")
            else:
                logger.info("‚ÑπÔ∏è RAG n√£o ativado: Mensagem sem enriquecimento")

            # Criar sess√£o de chat com hist√≥rico
            # Nota: Google Search Grounding n√£o √© suportado pelo gemini-pro com este SDK
            chat = self.model.start_chat(history=conversation_history or [])

            # Enviar mensagem enriquecida (com RAG se aplic√°vel)
            response = chat.send_message(enriched_message)

            # Verificar finish_reason
            finish_reason = response.candidates[0].finish_reason
            logger.info(f"gemini_service: Finish reason: {finish_reason}")

            # finish_reason pode ser:
            # 0 = FINISH_REASON_UNSPECIFIED
            # 1 = STOP (resposta completa - OK)
            # 2 = MAX_TOKENS (atingiu limite de tokens)
            # 3 = SAFETY (bloqueado por seguran√ßa)
            # 4 = RECITATION (bloqueado por recita√ß√£o/pl√°gio)
            # 5 = OTHER

            if finish_reason == 1:  # STOP - resposta completa
                bot_response = response.text.strip()
                logger.info(f"gemini_service: Resposta recebida com sucesso ({len(bot_response)} chars)")
                return bot_response

            elif finish_reason == 2:  # MAX_TOKENS
                logger.warning("gemini_service: Resposta atingiu limite de tokens")
                if response.text:
                    return response.text.strip() + "\n\n[Resposta foi cortada por limite de tamanho. Pe√ßa para continuar!]"
                else:
                    return "Desculpe, a resposta ficou muito longa. Pode reformular a pergunta de forma mais espec√≠fica? üìö"

            elif finish_reason == 3:  # SAFETY
                logger.warning("gemini_service: Resposta bloqueada por filtros de seguran√ßa")
                safety_ratings = response.candidates[0].safety_ratings
                logger.warning(f"gemini_service: Safety ratings: {safety_ratings}")

                return ("Ops! Parece que sua pergunta acionou os filtros de seguran√ßa. üîí "
                        "Vamos manter nossa conversa focada em literatura e livros? "
                        "Posso te ajudar com recomenda√ß√µes, an√°lises liter√°rias ou d√∫vidas sobre o CG.BookStore! üìö‚ú®")

            elif finish_reason == 4:  # RECITATION
                logger.warning("gemini_service: Resposta bloqueada por recita√ß√£o")
                return ("Essa resposta cont√©m muito conte√∫do de fontes existentes. "
                        "Posso reformular ou dar minha pr√≥pria perspectiva sobre o assunto? üìñ")

            else:  # UNSPECIFIED ou OTHER
                logger.error(f"gemini_service: Finish reason inesperado: {finish_reason}")
                if response.text:
                    return response.text.strip()
                else:
                    return ("Hmm, algo inesperado aconteceu. ü§î "
                            "Pode tentar perguntar de outra forma? Estou aqui para ajudar! üí¨")

        except genai.types.StopCandidateException as e:
            # Erro espec√≠fico de conte√∫do bloqueado
            logger.warning(f"gemini_service: Conte√∫do bloqueado pelo filtro: {e}")
            return ("N√£o consigo processar essa solicita√ß√£o espec√≠fica. üîí\n\n"
                    "Se voc√™ perguntou sobre buscar na internet: n√£o tenho essa capacidade!\n"
                    "Para informa√ß√µes atualizadas, recomendo:\n"
                    "üì∞ Nossa se√ß√£o de **Not√≠cias**\n"
                    "üîç Pesquisar no **Google**\n"
                    "üìö Consultar **Skoob** ou **Goodreads**\n\n"
                    "Posso ajudar com outra pergunta sobre livros? üìñ")
        except Exception as e:
            error_str = str(e).lower()
            # Se for erro de quota, propagar para a view fazer fallback
            if 'quota' in error_str or '429' in error_str or 'exceeded' in error_str or 'resourceexhausted' in error_str:
                logger.warning(f"gemini_service: Quota excedida, propagando para fallback: {e}")
                raise Exception(f"quota_exceeded: {e}")
            logger.error(f"gemini_service: Erro ao gerar resposta do chatbot: {e}")
            raise Exception(f"Erro ao processar mensagem: {e}")

    def format_history_for_gemini(
        self,
        messages: List[Dict[str, str]]
    ) -> List[Dict[str, any]]:
        """
        Formata hist√≥rico de mensagens para o formato esperado pelo Gemini.

        Args:
            messages: Lista de mensagens no formato:
                [{"role": "user", "content": "msg"}, {"role": "assistant", "content": "resp"}]

        Returns:
            Lista no formato do Gemini:
                [{"role": "user", "parts": ["msg"]}, {"role": "model", "parts": ["resp"]}]
        """
        formatted = []
        for msg in messages:
            role = "model" if msg["role"] == "assistant" else msg["role"]
            formatted.append({
                "role": role,
                "parts": [msg["content"]]
            })
        return formatted


# Inst√¢ncia singleton do servi√ßo
_chatbot_service = None


def get_gemini_service() -> GeminiChatbotService:
    """Retorna a inst√¢ncia singleton do servi√ßo de chatbot Gemini."""
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = GeminiChatbotService()
    return _chatbot_service


def get_chatbot_service():
    """
    Retorna o servi√ßo de chatbot configurado (Gemini ou Groq).

    Escolhe automaticamente baseado na vari√°vel AI_PROVIDER no .env:
    - 'gemini': Usa Google Gemini (padr√£o se n√£o especificado)
    - 'groq': Usa Groq AI (recomendado - mais r√°pido e free tier generoso)

    Returns:
        Inst√¢ncia do servi√ßo de chatbot (GeminiChatbotService ou GroqChatbotService)
    """
    ai_provider = getattr(settings, 'AI_PROVIDER', 'gemini').lower()

    logger.info(f"Usando provedor de IA: {ai_provider}")

    if ai_provider == 'groq':
        try:
            from .groq_service import get_groq_chatbot_service
            service = get_groq_chatbot_service()
            logger.info("‚úÖ Servi√ßo Groq inicializado com sucesso")
            return service
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar Groq: {e}")
            logger.info("‚ö†Ô∏è Fallback para Gemini")
            return get_gemini_service()
    else:
        # Padr√£o: Gemini
        return get_gemini_service()
