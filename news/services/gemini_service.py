"""
AI Service for News Agent
Servi√ßo unificado para filtragem e cria√ß√£o de artigos usando Groq ou Gemini.
Prioriza Groq (gratuito e r√°pido) com fallback para Gemini.
"""

from groq import Groq
import google.generativeai as genai
from typing import List, Dict, Optional
import json
import re
import logging
import time
from django.conf import settings

logger = logging.getLogger(__name__)


class GeminiNewsService:
    """
    Servi√ßo para processar not√≠cias com IA (Groq ou Gemini).
    
    Prioriza Groq (llama-3.3-70b) por ser gratuito e r√°pido.
    Falls back para Gemini se Groq n√£o dispon√≠vel.
    
    Exemplo de uso:
        service = GeminiNewsService()
        
        # Filtrar not√≠cias
        filtered = service.filter_and_rank_news(raw_news, limit=10)
        
        # Criar artigo
        article = service.create_article(news_data)
    """
    
    def __init__(self):
        self.groq_client = None
        self.gemini_model = None
        self.provider = None
        
        # Tentar Groq primeiro (prioridade)
        groq_key = getattr(settings, 'GROQ_API_KEY', '')
        if groq_key:
            try:
                self.groq_client = Groq(api_key=groq_key)
                self.provider = 'groq'
                self.model_name = 'llama-3.3-70b-versatile'
                logger.info(f"‚úÖ AI Service inicializado com Groq ({self.model_name})")
            except Exception as e:
                logger.warning(f"Groq indispon√≠vel: {e}")
        
        # Fallback para Gemini
        if not self.groq_client:
            gemini_key = getattr(settings, 'GEMINI_API_KEY', '')
            if gemini_key:
                genai.configure(api_key=gemini_key)
                self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
                self.provider = 'gemini'
                self.model_name = 'gemini-2.5-flash'
                logger.info(f"‚úÖ AI Service inicializado com Gemini ({self.model_name})")
        
        if not self.provider:
            logger.warning("‚ö†Ô∏è Nenhuma API de IA configurada. Servi√ßo funcionar√° em modo fallback.")
    
    def is_available(self) -> bool:
        """Verifica se o servi√ßo est√° dispon√≠vel."""
        return self.provider is not None
    
    def _call_ai(self, prompt: str, temperature: float = 0.3, max_tokens: int = 4096) -> str:
        """
        Chamada unificada para a IA (Groq ou Gemini).
        
        Returns:
            Resposta em texto da IA
        """
        if self.provider == 'groq':
            response = self.groq_client.chat.completions.create(
                messages=[{"role": "user", "content": prompt}],
                model=self.model_name,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            return response.choices[0].message.content
        
        elif self.provider == 'gemini':
            response = self.gemini_model.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                )
            )
            return response.text
        
        else:
            raise Exception("Nenhuma API de IA dispon√≠vel")
    
    def filter_and_rank_news(
        self, 
        news_items: List[Dict], 
        limit: int = 10
    ) -> List[Dict]:
        """
        Filtra e ranqueia not√≠cias por relev√¢ncia liter√°ria.
        """
        if not self.is_available():
            logger.warning("IA n√£o dispon√≠vel, retornando not√≠cias sem filtro")
            return self._fallback_filter(news_items, limit)
        
        if not news_items:
            return []
        
        try:
            start_time = time.time()
            
            items_to_analyze = news_items[:50]
            prompt = self._build_filter_prompt(items_to_analyze, limit)
            
            response_text = self._call_ai(prompt, temperature=0.3, max_tokens=4096)
            result = self._parse_json_response(response_text)
            
            elapsed = time.time() - start_time
            logger.info(f"‚úÖ {self.provider.upper()} filtrou {len(result)} not√≠cias de {len(items_to_analyze)} em {elapsed:.1f}s")
            
            # Enriquecer com dados originais
            enriched_result = []
            for item in result:
                original_idx = item.get('id', 0)
                if 0 <= original_idx < len(items_to_analyze):
                    original = items_to_analyze[original_idx].copy()
                    original.update({
                        'summary': item.get('summary', ''),
                        'relevance_score': item.get('relevance_score', 5),
                        'suggested_category': item.get('suggested_category', 'Geral'),
                        'suggested_tags': item.get('suggested_tags', []),
                    })
                    enriched_result.append(original)
            
            return enriched_result
            
        except Exception as e:
            logger.error(f"Erro ao filtrar com {self.provider}: {str(e)}")
            return self._fallback_filter(news_items, limit)
    
    def create_article(self, news_data: Dict) -> Dict:
        """
        Cria artigo completo a partir de dados da not√≠cia.
        Inclui valida√ß√£o anti-alucina√ß√£o.
        """
        if not self.is_available():
            raise Exception("Nenhuma API de IA dispon√≠vel. Configure GROQ_API_KEY ou GEMINI_API_KEY.")
        
        try:
            start_time = time.time()
            
            prompt = self._build_article_prompt(news_data)
            # Usar temperatura baixa para respostas mais factuais
            response_text = self._call_ai(prompt, temperature=0.3, max_tokens=4096)
            
            article = self._parse_json_response(response_text)
            
            # Validar conte√∫do contra alucina√ß√µes
            content = article.get('content', '')
            if self._has_hallucination_patterns(content):
                logger.warning("‚ö†Ô∏è Conte√∫do com poss√≠veis alucina√ß√µes detectadas, rejeitando...")
                raise ValueError("Artigo cont√©m padr√µes de alucina√ß√£o")
            
            # Adicionar metadados
            article['processing_time'] = time.time() - start_time
            article['ai_model'] = self.model_name
            
            logger.info(f"‚úÖ Artigo criado: '{article.get('title', '')[:50]}...' em {article['processing_time']:.1f}s")
            
            return article
            
        except Exception as e:
            logger.error(f"Erro ao criar artigo com {self.provider}: {str(e)}")
            raise
    
    def _has_hallucination_patterns(self, content: str) -> bool:
        """Detecta padr√µes de alucina√ß√£o e conte√∫do gen√©rico vazio."""
        
        content_lower = content.lower()
        
        # Padr√µes de placeholder
        placeholder_patterns = [
            'nome do autor', 'nome de autor', 'nomes de autores',
            't√≠tulo do livro', 't√≠tulo de livro', 't√≠tulos de livros',
            '[nome]', '[autor]', '[t√≠tulo]', '[data]',
            'nome de poeta', 't√≠tulo de quadrinho',
            'autores como', 'livros como', 'obras como',
            'exemplo de autor', 'exemplo de livro',
        ]
        
        for pattern in placeholder_patterns:
            if pattern in content_lower:
                logger.warning(f"Padr√£o de placeholder detectado: '{pattern}'")
                return True
        
        # Padr√µes de conte√∫do gen√©rico/vazio
        generic_patterns = [
            'lista com 100 t√≠tulos',
            'lista de 100 t√≠tulos', 
            'mais detalhes podem ser encontrados na fonte',
            'para saber mais, consulte',
            'para mais informa√ß√µes, acesse',
            'novos autores e obras',
            'vis√£o geral dos lan√ßamentos',
            'ferramenta valiosa para quem busca',
        ]
        
        generic_count = 0
        for pattern in generic_patterns:
            if pattern in content_lower:
                generic_count += 1
                logger.warning(f"Padr√£o gen√©rico detectado: '{pattern}'")
        
        # Se tem 2+ padr√µes gen√©ricos, √© conte√∫do vazio
        if generic_count >= 2:
            logger.warning(f"Conte√∫do muito gen√©rico ({generic_count} padr√µes)")
            return True
        
        # Verificar se conte√∫do √© muito curto (menos de 300 palavras)
        word_count = len(content.split())
        if word_count < 150:
            logger.warning(f"Conte√∫do muito curto: {word_count} palavras")
            return True
        
        return False
    
    def _build_filter_prompt(self, news_items: List[Dict], limit: int) -> str:
        """Constr√≥i prompt para filtrar not√≠cias."""
        
        news_text = "\n\n".join([
            f"ID: {i}\n"
            f"T√≠tulo: {item['title']}\n"
            f"Descri√ß√£o: {item['description'][:300]}...\n"
            f"Fonte: {item['source_name']}"
            for i, item in enumerate(news_items)
        ])
        
        prompt = f"""Voc√™ √© um curador especializado em literatura para o blog CGBookStore.

ANALISE as seguintes {len(news_items)} not√≠cias sobre literatura:

{news_text}

---

TAREFA:
1. Selecione as {limit} not√≠cias MAIS RELEVANTES para leitores apaixonados por literatura
2. Para cada not√≠cia, crie um resumo em portugu√™s brasileiro (100-150 palavras)

PRIORIZE: Lan√ßamentos de livros, entrevistas com autores, pr√™mios liter√°rios, eventos liter√°rios, adapta√ß√µes.
EVITE: Pol√≠tica, celebridades n√£o-autores, not√≠cias superficiais.

CATEGORIAS: "Lan√ßamentos", "Autores", "Mercado Editorial", "Pr√™mios", "Eventos", "Adapta√ß√µes", "Geral"

RETORNE APENAS JSON v√°lido:
[
  {{
    "id": 0,
    "relevance_score": 9.5,
    "summary": "Resumo em portugu√™s...",
    "suggested_category": "Lan√ßamentos",
    "suggested_tags": ["tag1", "tag2", "tag3"]
  }}
]
"""
        return prompt
    
    def _build_article_prompt(self, news_data: Dict) -> str:
        """Constr√≥i prompt para criar artigo com regras anti-alucina√ß√£o."""
        
        title = news_data.get('title', '')
        summary = news_data.get('summary', news_data.get('description', ''))
        source_name = news_data.get('source_name', '')
        link = news_data.get('link', '')
        
        prompt = f"""Voc√™ √© um jornalista liter√°rio do blog CGBookStore.

NOT√çCIA ORIGINAL:
T√≠tulo: {title}
Resumo: {summary}
Fonte: {source_name}
Link: {link}

---

REGRAS OBRIGAT√ìRIAS (SIGA RIGOROSAMENTE):

‚ö†Ô∏è REGRA ANTI-ALUCINA√á√ÉO:
1. Use APENAS informa√ß√µes presentes na not√≠cia original acima
2. N√ÉO invente nomes de autores, t√≠tulos de livros, datas ou dados
3. N√ÉO use placeholders como "nome do autor", "t√≠tulo do livro"
4. Se n√£o souber uma informa√ß√£o espec√≠fica, N√ÉO mencione
5. NUNCA afirme fatos que n√£o estejam na not√≠cia original

üìù FORMATO DO ARTIGO:
- T√≠tulo: M√°ximo 70 caracteres, baseado no conte√∫do real
- Conte√∫do: 400-600 palavras (N√ÉO invente para preencher)
- Use HTML: <p>, <h2>, <strong>, <em>
- Escreva em portugu√™s brasileiro

‚úÖ O QUE VOC√ä PODE FAZER:
- Resumir e reformular a informa√ß√£o original
- Adicionar contexto GERAL sobre o tema (sem inventar fatos espec√≠ficos)
- Opinar sobre a relev√¢ncia da not√≠cia
- Mencionar que "mais detalhes podem ser encontrados na fonte"

‚ùå O QUE VOC√ä N√ÉO PODE FAZER:
- Inventar nomes de autores que n√£o est√£o na not√≠cia
- Criar listas de livros fict√≠cias
- Afirmar datas ou n√∫meros n√£o confirmados
- Usar express√µes gen√©ricas como "autores como [nome]"

RETORNE APENAS JSON v√°lido:
{{
  "title": "T√≠tulo baseado na not√≠cia real",
  "content": "Conte√∫do em HTML baseado APENAS na not√≠cia",
  "excerpt": "Resumo de 150-200 caracteres",
  "meta_description": "Meta description 150 chars",
  "tags": ["tag1", "tag2", "tag3"]
}}
"""
        return prompt
    
    def _parse_json_response(self, response_text: str) -> any:
        """Parse da resposta JSON com tratamento robusto."""
        
        # Remover markdown code blocks
        text = re.sub(r'```json\s*', '', response_text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        # Tentar encontrar JSON v√°lido
        if text.startswith('['):
            match = re.search(r'\[[\s\S]*\]', text)
        else:
            match = re.search(r'\{[\s\S]*\}', text)
        
        if match:
            text = match.group(0)
        
        # Tentar parse direto
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        # Tentar corrigir problemas comuns
        try:
            # Remover caracteres de controle
            text = re.sub(r'[\x00-\x1f\x7f-\x9f]', ' ', text)
            # Escapar newlines dentro de strings
            text = re.sub(r'(?<!\\)\n', '\\n', text)
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        # √öltima tentativa: extrair campos manualmente
        try:
            if '"title"' in text and '"content"' in text:
                title_match = re.search(r'"title"\s*:\s*"([^"]*)"', text)
                content_match = re.search(r'"content"\s*:\s*"([\s\S]*?)"(?=\s*[,}])', text)
                excerpt_match = re.search(r'"excerpt"\s*:\s*"([^"]*)"', text)
                meta_match = re.search(r'"meta_description"\s*:\s*"([^"]*)"', text)
                tags_match = re.search(r'"tags"\s*:\s*\[(.*?)\]', text)
                
                article = {
                    'title': title_match.group(1) if title_match else 'Artigo',
                    'content': content_match.group(1) if content_match else '<p>Conte√∫do n√£o dispon√≠vel</p>',
                    'excerpt': excerpt_match.group(1) if excerpt_match else '',
                    'meta_description': meta_match.group(1) if meta_match else '',
                    'tags': []
                }
                
                if tags_match:
                    tags_str = tags_match.group(1)
                    article['tags'] = re.findall(r'"([^"]*)"', tags_str)
                
                logger.info("JSON parseado com m√©todo de fallback")
                return article
        except Exception as e:
            logger.warning(f"Fallback parser falhou: {e}")
        
        logger.error(f"Erro ao parsear JSON")
        logger.debug(f"Resposta: {response_text[:1000]}...")
        raise json.JSONDecodeError("N√£o foi poss√≠vel parsear a resposta", text, 0)
    
    def _fallback_filter(self, news_items: List[Dict], limit: int) -> List[Dict]:
        """Fallback: retorna as mais recentes."""
        sorted_items = sorted(
            news_items, 
            key=lambda x: (x.get('source_priority', 0), x.get('published_date', '')),
            reverse=True
        )
        return sorted_items[:limit]
